<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>feeday</title><link>https://feeday.cn</link><description>BB Work No Money</description><copyright>feeday</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://github.githubassets.com/favicons/favicon.svg</url><title>avatar</title><link>https://feeday.cn</link></image><lastBuildDate>Sun, 28 Sep 2025 16:04:42 +0000</lastBuildDate><managingEditor>feeday</managingEditor><ttl>60</ttl><webMaster>feeday</webMaster><item><title>é›¾é’Ÿå··Â·è¶æ¢¦ï½œå ä½ç¨¿ 2025-09-28</title><link>https://feeday.cn/post/wu-zhong-xiang-%C2%B7-die-meng-%EF%BD%9C-zhan-wei-gao-%202025-09-28.html</link><description>&gt; è¿™æ˜¯è‡ªåŠ¨å†™ä½œå ä½ç¨¿ï¼ˆæ—  API ç‰ˆï¼‰ï¼Œç”¨äºéªŒè¯â€œè‡ªåŠ¨åˆ›å»º Issue â†’ å‘å¸ƒç«™ç‚¹â€çš„æµæ°´çº¿ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/wu-zhong-xiang-%C2%B7-die-meng-%EF%BD%9C-zhan-wei-gao-%202025-09-28.html</guid><pubDate>Sun, 28 Sep 2025 14:05:50 +0000</pubDate></item><item><title>é›¾é’Ÿå··Â·è¶æ¢¦ï½œå ä½ç¨¿ 2025-09-27</title><link>https://feeday.cn/post/wu-zhong-xiang-%C2%B7-die-meng-%EF%BD%9C-zhan-wei-gao-%202025-09-27.html</link><description>&gt; è¿™æ˜¯è‡ªåŠ¨å†™ä½œå ä½ç¨¿ï¼ˆæ—  API ç‰ˆï¼‰ï¼Œç”¨äºéªŒè¯â€œè‡ªåŠ¨åˆ›å»º Issue â†’ å‘å¸ƒç«™ç‚¹â€çš„æµæ°´çº¿ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/wu-zhong-xiang-%C2%B7-die-meng-%EF%BD%9C-zhan-wei-gao-%202025-09-27.html</guid><pubDate>Sat, 27 Sep 2025 14:06:12 +0000</pubDate></item><item><title>é›¾é’Ÿå··Â·è¶æ¢¦ï½œå ä½ç¨¿ 2025-09-26</title><link>https://feeday.cn/post/wu-zhong-xiang-%C2%B7-die-meng-%EF%BD%9C-zhan-wei-gao-%202025-09-26.html</link><description>&gt; è¿™æ˜¯è‡ªåŠ¨å†™ä½œå ä½ç¨¿ï¼ˆæ—  API ç‰ˆï¼‰ï¼Œç”¨äºéªŒè¯â€œè‡ªåŠ¨åˆ›å»º Issue â†’ å‘å¸ƒç«™ç‚¹â€çš„æµæ°´çº¿ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/wu-zhong-xiang-%C2%B7-die-meng-%EF%BD%9C-zhan-wei-gao-%202025-09-26.html</guid><pubDate>Fri, 26 Sep 2025 14:06:11 +0000</pubDate></item><item><title>è±†åŒ… API</title><link>https://feeday.cn/post/dou-bao-%20API.html</link><description>## æ¨¡å‹å®šä»·
- [åœ¨çº¿ç”Ÿæˆ](https://console.volcengine.com/ark/region:ark+cn-beijing/model/detail?Id=doubao-seededit-3-0-i2i)
- [ä½¿ç”¨é‡æŸ¥çœ‹](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&amp;OpenTokenDrawer=false&amp;tab=ComputerVision)

æ¨¡å‹åç§° | å®šä»·å…ƒ/å¼ 
-- | --
doubao-seedream-4.0 | 0.2
doubao-seedream-3.0-t2i | 0.259
doubao-seededit-3.0-i2i | 0.3


## è±†åŒ…å›¾åƒè¯†åˆ«

```
import os
import sys
import subprocess

# ===== å®‰è£…ä¾èµ– =====
def install(package):
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', package])

install('openai&gt;=1.0')

from openai import OpenAI

# åˆå§‹åŒ– Ark å®¢æˆ·ç«¯ï¼ˆå»ºè®®æ–¹å¼ï¼šä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
client = OpenAI(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key='xxxx',
)

# è°ƒç”¨æ¨¡å‹
response = client.chat.completions.create(
    model='doubao-1-5-vision-pro-32k-250115',
    messages=[
        {
            'role': 'user',
            'content': [
                {
                    'type': 'image_url',
                    'image_url': {
                        'url': 'https://ark-project.tos-cn-beijing.ivolces.com/images/view.jpeg'
                    },
                },
                {'type': 'text', 'text': 'è¿™æ˜¯å“ªé‡Œï¼Ÿ'},
            ],
        }
    ],
)

print(response.choices[0].message)
```

## è±†åŒ…å›¾åƒä¿®æ”¹

```
import os
import sys
import subprocess

# ===== è‡ªåŠ¨å®‰è£…ä¾èµ– =====
def install(package):
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', package])

install('volcengine-python-sdk[ark]')

# ===== å¯¼å…¥ SDK =====
from volcenginesdkarkruntime import Ark

# åˆå§‹åŒ– Ark å®¢æˆ·ç«¯
client = Ark(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key='xxxx',
)

# è°ƒç”¨å›¾ç‰‡ç”Ÿæˆæ¥å£
imagesResponse = client.images.generate(
    model='doubao-seededit-3-0-i2i-250628',
    prompt='æ”¹æˆçˆ±å¿ƒå½¢çŠ¶çš„æ³¡æ³¡',
    image='https://ark-project.tos-cn-beijing.volces.com/doc_image/seededit_i2i.jpeg',
    seed=123,
    guidance_scale=5.5,
    size='adaptive',
    watermark=True
)

# æ‰“å°è¿”å›å›¾ç‰‡åœ°å€
print(imagesResponse.data[0].url)
```

## è±†åŒ…æ”¹å›¾ä¸‹è½½æœ¬åœ°

```
import os
import sys
import subprocess
import requests

# ===== è‡ªåŠ¨å®‰è£…ä¾èµ– =====
def install(package):
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', package])

try:
    from volcenginesdkarkruntime import Ark
except ImportError:
    install('volcengine-python-sdk[ark]')
    from volcenginesdkarkruntime import Ark

# ===== åˆå§‹åŒ– Ark å®¢æˆ·ç«¯ =====
client = Ark(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key='xxx',  # å»ºè®®æ”¹æˆ os.getenv('ARK_API_KEY')
)

# ===== é…ç½® =====
TXT_FILE = r'c:\prompts.txt'   # æç¤ºè¯æ–‡ä»¶
SAVE_DIR = r'C:\doubao\i2i'   # ä¸‹è½½ä¿å­˜ç›®å½•
os.makedirs(SAVE_DIR, exist_ok=True)

# ===== è¯»å–æç¤ºè¯æ–‡ä»¶å¹¶é€è¡Œè°ƒç”¨ =====
with open(TXT_FILE, 'r', encoding='utf-8') as f:
    prompts = [line.strip() for line in f if line.strip()]

for idx, prompt in enumerate(prompts, start=1):
    try:
        imagesResponse = client.images.generate(
            model='doubao-seededit-3-0-i2i-250628',
            prompt=prompt,  # æ¯è¡Œä½œä¸ºæç¤ºè¯
            image='https://ark-project.tos-cn-beijing.volces.com/doc_image/seededit_i2i.jpeg',
            seed=123,
            guidance_scale=5.5,
            size='adaptive',
            watermark=True
        )
        url = imagesResponse.data[0].url
        print(f'[{idx}] æç¤ºè¯: {prompt} -&gt; å›¾ç‰‡åœ°å€: {url}')

        # ===== ä¸‹è½½å›¾ç‰‡ =====
        resp = requests.get(url, timeout=60)
        if resp.status_code == 200:
            # æ–‡ä»¶åï¼šåºå·_å‰10ä¸ªå­—ç¬¦æç¤ºè¯.jpg
            safe_prompt = ''.join(c for c in prompt if c.isalnum())[:10]
            filename = os.path.join(SAVE_DIR, f'{idx:03d}_{safe_prompt}.jpg')
            with open(filename, 'wb') as f:
                f.write(resp.content)
            print(f'    å·²ä¿å­˜åˆ°: {filename}')
        else:
            print(f'    ä¸‹è½½å¤±è´¥: HTTP {resp.status_code}')

    except Exception as e:
        print(f'[{idx}] æç¤ºè¯: {prompt} -&gt; ç”Ÿæˆå¤±è´¥: {e}')
```

## æœ¬åœ°å›¾ç‰‡æ‰¹é‡ä¿®æ”¹

```
import os
import sys
import subprocess
import base64
import mimetypes
import requests
import re
from time import sleep

# ===== è‡ªåŠ¨å®‰è£…ä¾èµ– =====
def install(package):
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', package])

try:
    from volcenginesdkarkruntime import Ark
except ImportError:
    install('volcengine-python-sdk[ark]')
    from volcenginesdkarkruntime import Ark

# ===== å·¥å…·å‡½æ•° =====
def to_data_url(img_path: str) -&gt; str:
    '''æŠŠæœ¬åœ°å›¾ç‰‡è½¬æˆ data URL: data:image/xxx;base64,xxxx'''
    with open(img_path, 'rb') as f:
        b64 = base64.b64encode(f.read()).decode('utf-8')
    mime, _ = mimetypes.guess_type(img_path)
    if not mime:
        mime = 'image/jpeg'
    return f'data:{mime};base64,{b64}'

def download(url: str, out_path: str, timeout: int = 60, retry: int = 3) -&gt; bool:
    for i in range(1, retry + 1):
        try:
            r = requests.get(url, timeout=timeout)
            if r.status_code == 200:
                with open(out_path, 'wb') as f:
                    f.write(r.content)
                return True
            else:
                print(f'    [ä¸‹è½½] HTTP {r.status_code}ï¼ˆ{i}/{retry}ï¼‰')
        except Exception as e:
            print(f'    [ä¸‹è½½] å¼‚å¸¸ï¼š{e}ï¼ˆ{i}/{retry}ï¼‰')
        sleep(1)
    return False

def natural_key(s: str):
    '''è‡ªç„¶æ’åº keyï¼Œç¡®ä¿ 2.jpg &lt; 10.jpg'''
    return [int(text) if text.isdigit() else text.lower()
            for text in re.split(r'(\d+)', s)]

# ===== åˆå§‹åŒ– Ark å®¢æˆ·ç«¯ =====
client = Ark(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=os.getenv('ARK_API_KEY', 'xxx'),  # æ¨èæ”¹ç”¨ç¯å¢ƒå˜é‡
)

# ===== è·¯å¾„é…ç½® =====
IMG_DIR  = r'C:\doubao\188'     # è¾“å…¥åŸå›¾ç›®å½•
SAVE_DIR = r'C:\doubao\i2i'    # è¾“å‡ºç›®å½•
TXT_FILE = r'C:\prompts.txt'   # æç¤ºè¯æ–‡ä»¶
os.makedirs(SAVE_DIR, exist_ok=True)

# ===== è¯»å–æç¤ºè¯ =====
with open(TXT_FILE, 'r', encoding='utf-8') as f:
    prompts = [line.strip() for line in f if line.strip()]
if not prompts:
    raise RuntimeError('prompts.txt ä¸ºç©ºï¼šè¯·è‡³å°‘æä¾›ä¸€è¡Œæç¤ºè¯ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/dou-bao-%20API.html</guid><pubDate>Thu, 25 Sep 2025 14:01:00 +0000</pubDate></item><item><title>srt åˆ‡è§†é¢‘éŸ³é¢‘</title><link>https://feeday.cn/post/srt%20-qie-shi-pin-yin-pin.html</link><description>## æŒ‰å­—å¹•åˆ‡å‰²éŸ³é¢‘è§†é¢‘
```
# -*- coding: utf-8 -*-
'''
cut_by_srt_auto.py
- è‡ªåŠ¨ pip å®‰è£…ä¾èµ– (srt, chardet, tqdm)
- è‡ªåŠ¨åŒ¹é…ç½®é¡¶æ–‡ä»¶å¤¹é‡Œçš„åª’ä½“æ–‡ä»¶ (mp4/mp3/wav/mkvç­‰)
- æ‰¾åˆ°å¯¹åº”åŒå .srt æ–‡ä»¶
- æŒ‰å­—å¹•æ—¶é—´åˆ‡ç‰‡ï¼Œå¹¶è¾“å‡ºåˆ° ã€åŸæ–‡ä»¶å_clipsã€‘æ–‡ä»¶å¤¹
'''

import os
import sys
import subprocess
import importlib.util
from pathlib import Path
import re
from datetime import timedelta

# ==== è‡ªåŠ¨å®‰è£…ä¾èµ– ====
def pip_install(package):
    try:
        __import__(package)
    except ImportError:
        print(f'[INFO] å®‰è£…ä¾èµ–: {package}')
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])

for pkg in ['srt', 'chardet', 'tqdm']:
    pip_install(pkg)

import srt
import chardet
from tqdm import tqdm

# ==== å·¥å…·å‡½æ•° ====
def detect_encoding(p):
    raw = Path(p).read_bytes()
    enc = chardet.detect(raw).get('encoding') or 'utf-8'
    try:
        raw.decode(enc)
    except Exception:
        enc = 'utf-8'
    return enc

def td2ss(t: timedelta):
    return t.total_seconds()

def ss2tc(seconds: float):
    ms = int(round(seconds * 1000))
    h = ms // 3600000
    m = (ms % 3600000) // 60000
    s = (ms % 60000) // 1000
    ms = ms % 1000
    return f'{h:02d}:{m:02d}:{s:02d}.{ms:03d}'

def safe_name(text, keep=30):
    text = re.sub(r'[\\/:*?\'&lt;&gt;|]', '_', text.strip())
    text = re.sub(r'\s+', ' ', text)
    return text[:keep] if text else 'clip'

# ==== ä¸»é€»è¾‘ ====
def main():
    base = Path(__file__).parent  # å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•ï¼ˆç½®é¡¶æ–‡ä»¶å¤¹ï¼‰
    # æ‰¾åª’ä½“æ–‡ä»¶
    media_files = list(base.glob('*.mp4')) + list(base.glob('*.mkv')) + list(base.glob('*.mp3')) + list(base.glob('*.wav'))
    if not media_files:
        print('[ERROR] æ²¡æ‰¾åˆ°åª’ä½“æ–‡ä»¶ï¼ˆæ”¯æŒ mp4/mkv/mp3/wavï¼‰')
        return
    media = media_files[0]  # é»˜è®¤å–ç¬¬ä¸€ä¸ª
    print(f'[INFO] ä½¿ç”¨åª’ä½“æ–‡ä»¶: {media}')

    # æ‰¾ srt æ–‡ä»¶ï¼ˆåŒåï¼‰
    srt_file = media.with_suffix('.srt')
    if not srt_file.exists():
        print(f'[ERROR] æ²¡æ‰¾åˆ°å¯¹åº”å­—å¹•æ–‡ä»¶: {srt_file}')
        return
    print(f'[INFO] ä½¿ç”¨å­—å¹•æ–‡ä»¶: {srt_file}')

    # è¾“å‡ºç›®å½•
    outdir = base / f'{media.stem}_clips'
    outdir.mkdir(exist_ok=True)

    # è¯»å–å­—å¹•
    enc = detect_encoding(srt_file)
    text = srt_file.read_text(encoding=enc, errors='ignore')
    subs = list(srt.parse(text))

    total = 0
    for i, sub in enumerate(tqdm(subs, desc='Cutting', unit='seg'), start=1):
        start_s = td2ss(sub.start)
        end_s = td2ss(sub.end)

        ss = ss2tc(start_s)
        to = ss2tc(end_s)

        snippet = sub.content.replace('\n', ' ').strip()
        name_text = safe_name(snippet, keep=20)

        ext = '.mp4' if media.suffix.lower() in ['.mp4', '.mkv'] else '.m4a'
        out_path = outdir / f'{i:03d}_{name_text}{ext}'

        cmd = [
            'ffmpeg', '-y', '-hide_banner', '-loglevel', 'error',
            '-ss', ss, '-to', to, '-i', str(media),
            '-c:v', 'libx264', '-preset', 'veryfast', '-crf', '23',
            '-c:a', 'aac', '-b:a', '128k',
            str(out_path)
        ]
        try:
            subprocess.run(cmd, check=True)
            total += 1
        except subprocess.CalledProcessError:
            print(f'[WARN] ç¬¬ {i} æ®µå¯¼å‡ºå¤±è´¥')

    print(f'[å®Œæˆ] å…±å¯¼å‡º {total} æ®µ -&gt; {outdir}')

if __name__ == '__main__':
    main()
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/srt%20-qie-shi-pin-yin-pin.html</guid><pubDate>Sun, 21 Sep 2025 10:46:32 +0000</pubDate></item><item><title>Gitea ç®¡ç†è„šæœ¬</title><link>https://feeday.cn/post/Gitea%20-guan-li-jiao-ben.html</link><description># éƒ¨ç½² Gitea
```
#!/bin/bash
# Gitea ç®¡ç†è„šæœ¬ï¼šå®‰è£…å‰å…ˆå¸è½½æ—§çš„
set -e

GITEA_VERSION='1.22.3'                          # è¦å®‰è£…çš„ç‰ˆæœ¬
GITEA_BIN='/usr/local/bin/gitea'
GITEA_USER='git'
GITEA_HOME='/var/lib/gitea'
GITEA_CONF='/etc/gitea'
SERVICE_FILE='/etc/systemd/system/gitea.service'

uninstall_gitea() {
    echo 'âš ï¸ å¸è½½æ—§ç‰ˆ Gitea ...'
    systemctl stop gitea &gt;/dev/null 2&gt;&amp;1 || true
    systemctl disable gitea &gt;/dev/null 2&gt;&amp;1 || true
    rm -f $SERVICE_FILE
    rm -f $GITEA_BIN
    systemctl daemon-reload
    echo 'âœ… å¸è½½å®Œæˆï¼ˆæ•°æ®ç›®å½• $GITEA_HOME å’Œé…ç½® $GITEA_CONF ä¿ç•™ï¼‰'
}

install_gitea() {
    echo 'ğŸ“¥ å¼€å§‹å®‰è£… Gitea v${GITEA_VERSION} ...'
    # å¸è½½æ—§ç‰ˆæœ¬
    uninstall_gitea

    # åˆ›å»ºç”¨æˆ·å’Œç›®å½•
    id -u $GITEA_USER &amp;&gt;/dev/null || useradd -r -m -d $GITEA_HOME -s /bin/bash $GITEA_USER
    mkdir -p $GITEA_HOME/{custom,data,log} $GITEA_CONF
    chown -R $GITEA_USER:$GITEA_USER $GITEA_HOME $GITEA_CONF

    # ä¸‹è½½äºŒè¿›åˆ¶
    wget -O $GITEA_BIN 'https://dl.gitea.com/gitea/${GITEA_VERSION}/gitea-${GITEA_VERSION}-linux-amd64'
    chmod +x $GITEA_BIN

    # å†™ systemd æœåŠ¡
    cat &gt; $SERVICE_FILE &lt;&lt;EOF
[Unit]
Description=Gitea
After=syslog.target
After=network.target
Requires=network.target

[Service]
RestartSec=2s
Type=simple
User=$GITEA_USER
Group=$GITEA_USER
WorkingDirectory=$GITEA_HOME
ExecStart=$GITEA_BIN web --config $GITEA_CONF/app.ini
Restart=always
Environment=USER=$GITEA_USER HOME=$GITEA_HOME GITEA_WORK_DIR=$GITEA_HOME

[Install]
WantedBy=multi-user.target
EOF

    systemctl daemon-reload
    systemctl enable gitea
    systemctl start gitea
    echo 'âœ… å®‰è£…å®Œæˆï¼è®¿é—® http://ä½ çš„IP:3000 åˆå§‹åŒ–'
}

restart_gitea() {
    echo 'ğŸ”„ æ­£åœ¨é‡å¯ Gitea ...'
    systemctl restart gitea
    echo 'âœ… å·²é‡å¯'
}

stop_gitea() {
    echo 'â¹ï¸ æ­£åœ¨åœæ­¢ Gitea ...'
    systemctl stop gitea
    echo 'âœ… å·²åœæ­¢'
}

menu() {
    echo '===== Gitea ç®¡ç† ====='
    echo '1) å®‰è£…æœ€æ–° Giteaï¼ˆä¼šè‡ªåŠ¨å¸è½½æ—§ç‰ˆï¼‰'
    echo '2) å¸è½½ Gitea'
    echo '3) é‡å¯ Gitea'
    echo '4) åœæ­¢ Gitea'
    echo '======================'
    read -p 'è¯·é€‰æ‹©æ“ä½œ: ' choice

    case $choice in
        1) install_gitea ;;
        2) uninstall_gitea ;;
        3) restart_gitea ;;
        4) stop_gitea ;;
        *) echo 'æ— æ•ˆé€‰æ‹©' ;;
    esac
}

menu
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/Gitea%20-guan-li-jiao-ben.html</guid><pubDate>Sat, 13 Sep 2025 05:29:30 +0000</pubDate></item><item><title>CentOS 7.6  SSH é˜²æš´åŠ›ç ´è§£</title><link>https://feeday.cn/post/CentOS%207.6%20%20SSH%20-fang-bao-li-po-jie.html</link><description>#  æ™®é€šè¿æ¥

```
ssh -p 22 root@192.168.1.1
```

#  å¯†é’¥è¿æ¥

- https://github.com/settings/ssh/new

```
ssh-keygen -t rsa -b 4096 -C '123@qq.com'
type C:\.ssh\id_rsa.pub

ssh -i &lt;ç§é’¥æ–‡ä»¶è·¯å¾„&gt; &lt;ç”¨æˆ·å&gt;@&lt;æœåŠ¡å™¨IP&gt;

ssh -T git@github.com
git@github.com:tcq20256/feeday.git
```

# å°ç¦æ”»å‡»çš„IP

```
#!/usr/bin/env bash
# setup_ssh_antibrute.sh
# CentOS 7.6ï¼šFail2Ban SSH é˜²æš´åŠ›ç ´è§£ï¼ˆå®‰è£…/é…ç½® + è‡ªæ„ˆä¿®å¤ ä¸€ä½“åŒ–ï¼‰
# - ä»…åŠ¨ fail2banï¼Œä¸æ”¹ sshd ç«¯å£/è®¤è¯æ–¹å¼ï¼Œä¸å½±å“å…¶ä»–æœåŠ¡
# - firewalld åœ¨è·‘ï¼šfirewallcmd-ipsetï¼ˆè¿è¡Œæ—¶è§„åˆ™ï¼Œéæ°¸ä¹…ï¼‰ï¼›å¦åˆ™ç”¨ iptables-multiport
# - BAN/UNBAN å®¡è®¡æ—¥å¿—å¯è‡ªå®šä¹‰è·¯å¾„ï¼ˆé»˜è®¤ /home/lighthouse/bash/ssh-ban.logï¼Œæˆ– BAN_LOG='__SCRIPT_DIR__'ï¼‰
# - æ£€æµ‹åˆ° socket è¿æ¥å¤±è´¥ä¼šè‡ªåŠ¨æ‰§è¡Œä¿®å¤æµç¨‹ï¼ˆæ¸…ç†æ®‹ç•™ã€é‡å»º /run/fail2banã€æ¢å¤ SELinux ä¸Šä¸‹æ–‡ã€è¡¥é½ iptablesï¼‰

set -euo pipefail

### ===== å¯è°ƒå‚æ•°ï¼ˆä¹Ÿå¯ç”¨ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰=====
BANTIME='${BANTIME:-3600}'     # è¢«å°æ—¶é•¿ï¼ˆç§’ï¼‰
FINDTIME='${FINDTIME:-600}'    # è§‚å¯Ÿçª—å£ï¼ˆç§’ï¼‰
MAXRETRY='${MAXRETRY:-5}'      # å¤±è´¥æ¬¡æ•°é˜ˆå€¼
MY_IP='${MY_IP:-}'             # å¯é€‰ï¼šä½ çš„å‡ºå£ç™½åå•ï¼Œå¦‚ 1.2.3.4
DEFAULT_BAN_LOG='/home/lighthouse/bash/ssh-ban.log'

# æ—¥å¿—ä½ç½®ï¼šæ”¯æŒ BAN_LOG='__SCRIPT_DIR__'
SCRIPT_DIR='$(cd -- '$(dirname -- '${BASH_SOURCE[0]}')' &amp;&amp; pwd)'
if [[ '${BAN_LOG:-}' == '__SCRIPT_DIR__' ]]; then
  BAN_LOG='${SCRIPT_DIR}/ssh-ban.log'
else
  BAN_LOG='${BAN_LOG:-$DEFAULT_BAN_LOG}'
fi

### ===== å°å·¥å…· =====
msg(){ echo -e '\033[1;32m[INFO]\033[0m $*'; }
warn(){ echo -e '\033[1;33m[WARN]\033[0m $*'; }
err(){ echo -e '\033[1;31m[ERR ]\033[0m $*'; }

require_root(){ [[ ${EUID:-$(id -u)} -eq 0 ]] || { err 'è¯·ç”¨ root è¿è¡Œï¼šsudo bash $0'; exit 1; }; }
file_put(){ # $1:path  $2:content
  local p='$1'; shift
  umask 022; cat &gt;'$p' &lt;&lt;&lt;'$*'
  chmod 0644 '$p'
}

### ===== ä¿®å¤æµç¨‹ï¼šæ¸…ç†æ®‹ç•™ / ç›®å½• / SELinux / ç»„ä»¶ =====
repair_fail2ban(){
  warn 'è§¦å‘è‡ªæ„ˆä¿®å¤ï¼šæ¸…ç†æ®‹ç•™å¹¶é‡å»ºè¿è¡Œç¯å¢ƒâ€¦â€¦'
  systemctl stop fail2ban || true
  pkill -9 -f fail2ban-server || true

  rm -rf /run/fail2ban /var/run/fail2ban
  install -d -m 755 -o root -g root /run/fail2ban
  ln -sfn /run/fail2ban /var/run/fail2ban

  # SELinuxï¼ˆè‹¥å¯ç”¨åˆ™æ¢å¤ä¸Šä¸‹æ–‡ï¼Œæ— å‰¯ä½œç”¨ï¼‰
  if command -v selinuxenabled &gt;/dev/null 2&gt;&amp;1 &amp;&amp; selinuxenabled; then
    restorecon -Rv /run/fail2ban || true
  fi

  # ç»„ä»¶å…œåº•ï¼šå½“å‰ banaction å¯èƒ½ç”¨åˆ° iptables
  yum install -y -q iptables iptables-services || true

  # ç¡®ä¿ fail2ban.conf ä½¿ç”¨æ ‡å‡† socket è·¯å¾„ï¼ˆä»…ä¿®æ­£ç¼ºå¤±/å¼‚å¸¸æƒ…å†µï¼‰
  local conf='/etc/fail2ban/fail2ban.conf'
  if [[ -f '$conf' ]]; then
    grep -qE '^\s*socket\s*=\s*/var/run/fail2ban/fail2ban\.sock' '$conf' || \
      sed -ri 's|^\s*socket\s*=.*|socket = /var/run/fail2ban/fail2ban.sock|g' '$conf'
    grep -qE '^\s*pidfile\s*=\s*/var/run/fail2ban/fail2ban\.pid' '$conf' || \
      sed -ri 's|^\s*pidfile\s*=.*|pidfile = /var/run/fail2ban/fail2ban.pid|g' '$conf'
  fi

  systemctl restart fail2ban
  sleep 1
}

### ===== ä¸»æµç¨‹ =====
require_root

# 1) å®‰è£…ä¾èµ–
if ! rpm -qa | grep -qiE '^epel-release'; then
  msg 'å®‰è£… epel-release ...'
  yum install -y epel-release
fi
if ! rpm -qa | grep -qiE '^fail2ban(-server)?'; then
  msg 'å®‰è£… fail2ban ...'
  yum install -y fail2ban
else
  msg 'fail2ban å·²å®‰è£…'
fi

# 2) æ£€æµ‹ firewalld
FIREWALLD_ACTIVE=0
if systemctl is-active firewalld &gt;/dev/null 2&gt;&amp;1; then
  FIREWALLD_ACTIVE=1
  msg 'firewalld è¿è¡Œä¸­ï¼šbanaction=firewallcmd-ipsetï¼ˆè¿è¡Œæ—¶è§„åˆ™ï¼Œéæ°¸ä¹…ï¼‰'
else
  warn 'firewalld æœªè¿è¡Œï¼šbanaction=iptables-multiport'
fi
BANACTION='iptables-multiport'
[[ $FIREWALLD_ACTIVE -eq 1 ]] &amp;&amp; BANACTION='firewallcmd-ipset'

# 3) è‡ªå®šä¹‰åŠ¨ä½œï¼šlog-banï¼ˆæ­£ç¡®ä½¿ç”¨ &lt;name&gt;/&lt;ip&gt;/&lt;port&gt;/&lt;failures&gt;ï¼›printf ç”¨ %%sï¼›date ç”¨ %%F %%Tï¼‰
file_put /etc/fail2ban/action.d/log-ban.local \
'[Definition]
actionban   = /bin/sh -c '\''printf '%%s\tBAN\tjail=&lt;name&gt;\tip=&lt;ip&gt;\tport=&lt;port&gt;\tfailures=&lt;failures&gt;\tsrc=%(src)s\n' '$(date '+%%F %%T')' &gt;&gt; %(logfile)s'\''
actionunban = /bin/sh -c '\''printf '%%s\tUNBAN\tjail=&lt;name&gt;\tip=&lt;ip&gt;\n' '$(date '+%%F %%T')' &gt;&gt; %(logfile)s'\'''
chmod 0644 /etc/fail2ban/action.d/log-ban.local

# 4) ç”Ÿæˆ jail.localï¼ˆä»…å¼€å¯ sshd ç›‘ç‹±ï¼‰
JAIL_LOCAL='/etc/fail2ban/jail.local'
if [[ -f '$JAIL_LOCAL' ]]; then
  cp -a '$JAIL_LOCAL' '${JAIL_LOCAL}.bak.$(date +%Y%m%d-%H%M%S)'
  msg 'å·²å¤‡ä»½åŸé…ç½®ï¼š${JAIL_LOCAL}.bak.*'
fi
IGNOREIP='127.0.0.1/8'
[[ -n '$MY_IP' ]] &amp;&amp; IGNOREIP='$IGNOREIP $MY_IP'
file_put '$JAIL_LOCAL' \
'[DEFAULT]
bantime   = ${BANTIME}
findtime  = ${FINDTIME}
maxretry  = ${MAXRETRY}
backend   = auto
ignoreip  = ${IGNOREIP}
banaction = ${BANACTION}

[sshd]
enabled  = true
port     = ssh
filter   = sshd
logpath  = /var/log/secure
action   = %(action_)s
           log-ban[logfile=${BAN_LOG}, src=/var/log/secure]
'
chmod 0644 '$JAIL_LOCAL'

# 5) æ—¥å¿—ä¸ logrotate
mkdir -p '$(dirname -- '$BAN_LOG')'
touch '$BAN_LOG'
chmod 0640 '$BAN_LOG'
chown root:root '$BAN_LOG'
file_put /etc/logrotate.d/ssh-ban \
'${BAN_LOG} {
    daily
    rotate 14
    missingok
    notifempty
    compress
    create 0640 root root
}
'

# 6) å…œåº•è¿è¡Œç›®å½•
install -d -m 755 -o root -g root /run/fail2ban
ln -sfn /run/fail2ban /var/run/fail2ban

# 7) è¯­æ³•æµ‹è¯• &amp; å¯åŠ¨
msg 'æ ¡éªŒ fail2ban é…ç½®è¯­æ³• ...'
if ! fail2ban-client -t; then
  err 'é…ç½®è¯­æ³•æ ¡éªŒå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šæ–¹è¾“å‡ºã€‚</description><guid isPermaLink="true">https://feeday.cn/post/CentOS%207.6%20%20SSH%20-fang-bao-li-po-jie.html</guid><pubDate>Sat, 13 Sep 2025 04:09:13 +0000</pubDate></item><item><title>ä¸‹è½½é“¾æ¥</title><link>https://feeday.cn/post/xia-zai-lian-jie.html</link><description>## è·å–é“¾æ¥
```
const links = document.getElementsByTagName('a');

// éå†æ‰€æœ‰é“¾æ¥å¹¶æŸ¥æ‰¾åŒ¹é… Hugging Face blob åœ°å€
for (const link of links) {
  const href = link.href;
  // åŒ¹é… datasets ä»“åº“ blob é“¾æ¥
  const urlRegex = /^https:\/\/huggingface\.co\/datasets\/[^/]+\/[^/]+\/blob\/[^/]+\/.+$/;
  if (urlRegex.test(href)) {
    // æ›¿æ¢ blob â†’ resolve
    const realUrl = href.replace('/blob/', '/resolve/');
    console.log('ç›´é“¾: ' + realUrl);
  }
}
```

## æ‰§è¡Œä¸‹è½½

```
# -*- coding: utf-8 -*-
'''
auto_paste_two_options.py
ä¸¤ä¸ªé€‰é¡¹ï¼š
1) å¼€å§‹ï¼šè¿›å…¥åæ ‡è·å–ç•Œé¢ â†’ F5 ä¿å­˜åæ ‡åè‡ªåŠ¨å¼€å§‹å¾ªç¯
0) é€€å‡º

å¾ªç¯é€»è¾‘ï¼š
- ä» TXT æ¯è¡Œè¯»å–
- ç‚¹å‡»è¾“å…¥æ¡† â†’ ç²˜è´´ â†’ å›è½¦(æˆ–ç‚¹å‡»æŒ‰é’®)
- é—´éš” N ç§’ç»§ç»­
'''

import os, sys, json, time, subprocess

# ===== ä¾èµ–è‡ªåŠ¨å®‰è£… =====
def ensure_packages():
    for p in ['pyautogui', 'keyboard', 'pyperclip']:
        try:
            __import__('pyautogui' if p=='pyautogui' else p)
        except Exception:
            print(f'[å®‰è£…] ç¼ºå°‘ {p}ï¼Œæ­£åœ¨å®‰è£…...')
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', p])
ensure_packages()

import pyautogui, keyboard, pyperclip

pyautogui.FAILSAFE = True
pyautogui.PAUSE = 0.03

CONFIG_FILE = 'auto_paste_config.json'
STATE_FILE  = 'auto_paste_state.json'

# ===== è¿™é‡ŒæŒ‰éœ€æ”¹é»˜è®¤å€¼ =====
DEFAULT_CONFIG = {
    'txt_file': r'c:\Users\Puck\Desktop\sid.txt',   # â† æ”¹æˆä½ çš„ txt è·¯å¾„
    'coords': {'click_target': None, 'submit_btn': None},
    'interval_sec': 180,                  # é—´éš”ç§’ï¼ˆ3åˆ†é’Ÿï¼‰
    'clear_before_paste': True,           # ç²˜è´´å‰ Ctrl+A æ¸…ç©º
    'press_enter_after_paste': True       # True=å›è½¦æäº¤ï¼›False=ç‚¹å‡» submit_btn
}

# ========== å·¥å…·å‡½æ•° ==========
def load_json(path, default=None):
    if os.path.exists(path):
        try:
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            pass
    return default

def save_json(path, data):
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def get_conf():
    conf = load_json(CONFIG_FILE, None)
    if conf is None:
        conf = DEFAULT_CONFIG.copy()
        save_json(CONFIG_FILE, conf)
    else:
        # è¡¥é½å­—æ®µ
        for k, v in DEFAULT_CONFIG.items():
            if k not in conf: conf[k] = v
        if 'coords' not in conf or not isinstance(conf['coords'], dict):
            conf['coords'] = {'click_target': None, 'submit_btn': None}
        conf['coords'].setdefault('click_target', None)
        conf['coords'].setdefault('submit_btn', None)
        save_json(CONFIG_FILE, conf)
    return conf

def click(xy):
    if not xy: return
    x, y = xy
    pyautogui.moveTo(x, y, duration=0.05)
    pyautogui.click()

def paste_text(text, clear_before=True):
    if clear_before:
        pyautogui.hotkey('ctrl', 'a'); time.sleep(0.05)
    pyperclip.copy(text); time.sleep(0.05)
    pyautogui.hotkey('ctrl', 'v')

def press_enter():
    pyautogui.press('enter')

def human_time(sec):
    m, s = divmod(int(sec), 60)
    h, m = divmod(m, 60)
    if h: return f'{h}å°æ—¶{m}åˆ†{s}ç§’'
    if m: return f'{m}åˆ†{s}ç§’'
    return f'{s}ç§’'

def countdown(total_sec):
    start = time.time()
    paused = False
    while True:
        if keyboard.is_pressed('esc'):
            print('\n[é€€å‡º] ESC è§¦å‘ï¼Œç»“æŸå¾ªç¯ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/xia-zai-lian-jie.html</guid><pubDate>Wed, 10 Sep 2025 15:58:07 +0000</pubDate></item><item><title>GPT5-é›¾é’Ÿå··-å½’é€”</title><link>https://feeday.cn/post/GPT5--wu-zhong-xiang---gui-tu.html</link><description>æ—è¿œåœ¨åŸå¸‚é‡Œä½åœ¨ä¸€é—´ä½çŸ®çš„éš”æ–­æˆ¿ï¼Œçª—å¤–æ˜¯ä¸€æ¡æ°¸è¿œæ½®ç€æ²¹çƒŸçš„èƒŒè¡—ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/GPT5--wu-zhong-xiang---gui-tu.html</guid><pubDate>Sat, 06 Sep 2025 09:34:40 +0000</pubDate></item><item><title>GPT5-é›¾é’Ÿå··-æ— åæ—¥</title><link>https://feeday.cn/post/GPT5--wu-zhong-xiang---wu-ming-ri.html</link><description>æ—è¿œæ‹–ç€è¡Œæä»å°ç«™å‡ºæ¥ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/GPT5--wu-zhong-xiang---wu-ming-ri.html</guid><pubDate>Thu, 04 Sep 2025 15:34:35 +0000</pubDate></item><item><title>GPT5-é¬¼æ•…äº‹-é›¾é’Ÿå··</title><link>https://feeday.cn/post/GPT5--gui-gu-shi---wu-zhong-xiang.html</link><description>## ä¸€

æ—è¿œå›åˆ°é›¾é’Ÿå··çš„æ—¶å€™ï¼Œå¤©åˆšä¸‹è¿‡ä¸€é˜µç»†é›¨ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/GPT5--gui-gu-shi---wu-zhong-xiang.html</guid><pubDate>Thu, 04 Sep 2025 14:50:12 +0000</pubDate></item><item><title>word åˆå¹¶æ–‡æ¡£</title><link>https://feeday.cn/post/word%20-he-bing-wen-dang.html</link><description>## æ–‡æ¡£è½¬æ¢docxååˆå¹¶
```
import os
import sys
import time
import shutil
import subprocess
from pathlib import Path

# ========== è‡ªåŠ¨å®‰è£…ä¾èµ– ==========
def install(package_name, import_name=None):
    try:
        __import__(import_name or package_name)
    except ImportError:
        print(f'âš™ï¸ æ­£åœ¨å®‰è£…ä¾èµ–: {package_name} ...')
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package_name])

install('python-docx', 'docx')
install('docxcompose', 'docxcompose')
try:
    __import__('win32com.client')
except ImportError:
    try:
        install('pywin32', 'win32com')
    except Exception:
        pass

from docx import Document
from docxcompose.composer import Composer

# ========== é…ç½® ==========
input_dir = r'D:\doc'            # å¾…åˆå¹¶ç›®å½•ï¼ˆå« .doc / .docxï¼‰
output_file = r'D:\merged.docx'  # è¾“å‡ºï¼ˆå¿…é¡» .docxï¼‰

# ========== å®šä½ soffice.exe ==========
def find_soffice_exe():
    candidates = [
        r'C:\Program Files\LibreOffice\program\soffice.exe',
        r'C:\Program Files (x86)\LibreOffice\program\soffice.exe',
    ]
    # ä¹Ÿæ”¯æŒä¾¿æºç‰ˆ/è‡ªå®šä¹‰å®‰è£…ï¼šåœ¨å¸¸è§ç›˜ç¬¦æœä¸€å±‚
    for drive in ['C:', 'D:', 'E:']:
        p = Path(drive + r'\LibreOffice\program\soffice.exe')
        if p.exists():
            candidates.insert(0, str(p))
    for p in candidates:
        if os.path.exists(p):
            return p
    # PATH ä¸­æŸ¥æ‰¾
    w = shutil.which('soffice')
    return w

def has_word():
    try:
        import win32com.client  # noqa
        return True
    except Exception:
        return False

# ========== è½¬æ¢å‡½æ•° ==========
def convert_doc_to_docx_with_soffice(soffice_path, doc_path):
    outdir = os.path.dirname(doc_path)
    print(f'ğŸ”„ LibreOffice è½¬æ¢: {doc_path}')
    try:
        subprocess.run(
            [soffice_path, '--headless', '--convert-to', 'docx', '--outdir', outdir, doc_path],
            check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True
        )
        new_path = doc_path + 'x'  # xxx.doc -&gt; xxx.docx
        for _ in range(30):
            if os.path.exists(new_path):
                break
            time.sleep(0.1)
        if os.path.exists(new_path):
            print(f'âœ… è½¬æ¢æˆåŠŸ: {new_path}')
            return new_path
        print(f'âŒ è½¬æ¢å¤±è´¥: æœªæ‰¾åˆ° {new_path}')
    except subprocess.CalledProcessError as e:
        print('âŒ LibreOffice è½¬æ¢å‡ºé”™ï¼š')
        print(e.stdout or str(e))
    return None

def convert_doc_to_docx_with_word(doc_path):
    print(f'ğŸ”„ Word è½¬æ¢: {doc_path}')
    try:
        import win32com.client as win32
        word = win32.gencache.EnsureDispatch('Word.Application')
        word.Visible = False
        doc = None
        new_path = doc_path + 'x'
        try:
            doc = word.Documents.Open(doc_path)
            doc.SaveAs(new_path, FileFormat=16)  # 16 = wdFormatXMLDocument (.docx)
        finally:
            if doc is not None:
                doc.Close(False)
            word.Quit()
        if os.path.exists(new_path):
            print(f'âœ… è½¬æ¢æˆåŠŸ: {new_path}')
            return new_path
        else:
            print(f'âŒ è½¬æ¢å¤±è´¥: æœªæ‰¾åˆ° {new_path}')
    except Exception as e:
        print(f'âŒ Word è½¬æ¢å‡ºé”™: {e}')
    return None

def convert_doc_to_docx(doc_path):
    soffice = find_soffice_exe()
    if soffice and os.path.exists(soffice):
        p = convert_doc_to_docx_with_soffice(soffice, doc_path)
        if p:
            return p
    if has_word():
        p = convert_doc_to_docx_with_word(doc_path)
        if p:
            return p
    print(f'âš ï¸ æ— æ³•è½¬æ¢ï¼ˆç¼ºå°‘ LibreOffice æˆ– Wordï¼‰ï¼š{doc_path}')
    return None

# ========== åˆå¹¶ ==========
def merge_docs(input_dir, output_file):
    if not output_file.lower().endswith('.docx'):
        base, _ = os.path.splitext(output_file)
        output_file = base + '.docx'
        print(f'â„¹ï¸ è¾“å‡ºå¼ºåˆ¶ä¸º .docxï¼š{output_file}')

    names = [f for f in os.listdir(input_dir)
             if f.lower().endswith(('.doc', '.docx')) and not f.startswith('~$')]
    names.sort()
    if not names:
        print('âš ï¸ ç›®å½•ä¸­æ²¡æœ‰ .doc / .docx æ–‡ä»¶ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/word%20-he-bing-wen-dang.html</guid><pubDate>Wed, 03 Sep 2025 10:23:23 +0000</pubDate></item><item><title>youtube-è§†é¢‘é¢„è§ˆ</title><link>https://feeday.cn/post/youtube--shi-pin-yu-lan.html</link><description># ğŸ¬ yt-dlp-youtube-web

åŸºäº **Python Flask** çš„ æ²¹ç®¡è§†é¢‘é¢„è§ˆï¼Œä»…ä¾›æµ‹è¯•ï¼Œé€‚é… Cookie éªŒè¯ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/youtube--shi-pin-yu-lan.html</guid><pubDate>Sat, 30 Aug 2025 17:54:41 +0000</pubDate></item><item><title>åˆ é™¤é‡å¤å›¾åƒ</title><link>https://feeday.cn/post/shan-chu-zhong-fu-tu-xiang.html</link><description>åˆ é™¤é‡å¤å›¾åƒ
## å®‰è£…ä¾èµ–
```
pip install opencv-python numpy keras tensorflow
```
## è„šæœ¬ç¨‹åº
```
import os
import cv2
import numpy as np
from keras.applications.resnet50 import ResNet50, preprocess_input

# åŠ è½½ResNet50æ¨¡å‹ç”¨äºæå–å›¾åƒç‰¹å¾
model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

def extract_image_features(image_path):
    image = cv2.imread(image_path)  # è¯»å–å›¾ç‰‡
    image = cv2.resize(image, (224, 224))  # è°ƒæ•´å›¾ç‰‡å¤§å°
    image = np.expand_dims(image, axis=0)  # æ‰©å±•ç»´åº¦
    image = preprocess_input(image)  # é¢„å¤„ç†å›¾ç‰‡
    
    features = model.predict(image)  # æå–ç‰¹å¾
    features = features.flatten()  # å±•å¹³ç‰¹å¾å‘é‡
    features /= np.linalg.norm(features)  # ç‰¹å¾å‘é‡å½’ä¸€åŒ–
    
    return features

def delete_duplicate_images(directory):
    images = []
    features = []
    to_delete = []
    
    # éå†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    for filename in os.listdir(directory):
        file_path = os.path.join(directory, filename)
        if os.path.isfile(file_path):
            try:
                image_features = extract_image_features(file_path)
                for i, feature in enumerate(features):
                    # è®¡ç®—å›¾åƒä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦
                    similarity = np.dot(image_features, feature) / (np.linalg.norm(image_features) * np.linalg.norm(feature))
                    if similarity &gt; 0.99:  # è®¾å®šä¸€ä¸ªé˜ˆå€¼ï¼Œåˆ¤æ–­å›¾ç‰‡æ˜¯å¦ç›¸ä¼¼
                        print(f'Found duplicate: {filename} and {images[i]}')
                        to_delete.append(file_path)
                        break
                else:
                    images.append(filename)
                    features.append(image_features)
            except Exception as e:
                print(f'Error processing {filename}: {e}')
    
    # åˆ é™¤é‡å¤çš„å›¾ç‰‡
    for file_path in to_delete:
        os.remove(file_path)
        print(f'Deleted duplicate image: {file_path}')

# è®¾ç½®å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
directory = r'D:\test'
delete_duplicate_images(directory)
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shan-chu-zhong-fu-tu-xiang.html</guid><pubDate>Wed, 20 Aug 2025 04:08:42 +0000</pubDate></item><item><title>æ­£åˆ™è¡¨è¾¾å¼</title><link>https://feeday.cn/post/zheng-ze-biao-da-shi.html</link><description>
# æ­£åˆ™è¡¨è¾¾å¼é€ŸæŸ¥ä¸ç¤ºä¾‹

---

## åŸºç¡€åŒ¹é…

| åŠŸèƒ½ | æ­£åˆ™ | ç¤ºä¾‹æ–‡æœ¬ | åŒ¹é…ç»“æœ |
|------|------|----------|----------|
| **éæ•°å­—** | `[^0-9]*` | `abc123` | `abc` |
| **éæ•°å­—ï¼ˆç®€å†™ï¼‰** | `\D+` | `A9B` | `A` |
| **n ä½æ•°å­—** | `\d{4}` | `2025-08` | `2025` |
| **è‡³å°‘ n ä½æ•°å­—** | `\d{3,}` | `abc12345xyz` | `12345` |
| **é•¿åº¦ 3â€“20 çš„ä»»æ„å­—ç¬¦** | `.{3,20}` | `hello` | `hello` |

---

## å¤šè¡Œæ¨¡å¼ï¼ˆ`(?m)`ï¼‰

| åŠŸèƒ½ | æ­£åˆ™ | ç¤ºä¾‹æ–‡æœ¬ | åŒ¹é…ç»“æœ |
|------|------|----------|----------|
| **æ¯è¡Œæœ€åä¸¤ä¸ªå­—ç¬¦** | `(?m).{2}$` | `abc\ndefg` | `bc`, `fg` |
| **æ¯è¡Œå¼€å¤´ä¸¤ä¸ªå­—ç¬¦** | `(?m)^.{2}` | `abc\ndefg` | `ab`, `de` |

---

## å­—ç¬¦ç±»

| åŠŸèƒ½ | æ­£åˆ™ | ç¤ºä¾‹æ–‡æœ¬ | åŒ¹é…ç»“æœ |
|------|------|----------|----------|
| **ä¸­æ–‡å­—ç¬¦** | `[\u4e00-\u9fa5]` | `ä½ å¥½123` | `ä½ `, `å¥½` |
| **ä¸­æ–‡å­—ç¬¦ï¼ˆæ¨èï¼‰** | `\p{Han}` | `æ±‰å­—abc` | `æ±‰`, `å­—` |
| **è‹±æ–‡å’Œæ•°å­—** | `[A-Za-z0-9]+` | `abc123!` | `abc123` |
| **æ•°å­—ã€å­—æ¯ã€ä¸‹åˆ’çº¿** | `[A-Za-z0-9_]+` | `abc_123!` | `abc_123` |
| **é•¿åº¦ 3â€“20 çš„æ•°å­—/å­—æ¯/ä¸‹åˆ’çº¿** | `[A-Za-z0-9_]{3,20}` | `abc_123` | `abc_123` |

---

## å¸¸ç”¨æå–è§„åˆ™

| åŠŸèƒ½ | æ­£åˆ™ | ç¤ºä¾‹æ–‡æœ¬ | åŒ¹é…ç»“æœ |
|------|------|----------|----------|
| **åŒ¹é… `(æ•°å­—)`** | `\(\d+\)` | `file(1).txt` | `(1)` |
| **é‚®ç®±** | `^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+$` | `test@example.com` | `test@example.com` |
| **ä¸­å›½å¤§é™†æ‰‹æœºå·** | `^1[3-9]\d{9}$` | `13812345678` | `13812345678` |

---

## URL åŒ¹é…ï¼ˆåŒå¼•å·åŒ…å›´ï¼‰

1. åŸå§‹ç‰ˆæœ¬ï¼ˆä¸å…è®¸åŸŸåä¸­æœ‰ `.`ï¼‰
```regex
https?:\/\/[^\s\/$.?#]+[^\s]*?(?=')
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/zheng-ze-biao-da-shi.html</guid><pubDate>Thu, 14 Aug 2025 14:46:44 +0000</pubDate></item><item><title>åˆ é™¤é‡å¤æ–‡ä»¶</title><link>https://feeday.cn/post/shan-chu-zhong-fu-wen-jian.html</link><description>## åˆ é™¤é‡å¤æ–‡ä»¶
```
import os
import re

# === é…ç½® ===
FOLDER = r'C:\Users\1'  # ç›®æ ‡ç›®å½•
RECURSIVE = False                    # True=é€’å½’å­æ–‡ä»¶å¤¹
DRY_RUN = False                       # True=é¢„æ¼”ï¼›ç¡®è®¤åæ”¹ä¸º False çœŸåˆ 

# è§„åˆ™ï¼šåªè¦â€œæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰â€é‡Œå‡ºç° (æ•°å­—) å°±è®¤å®šä¸ºå‰¯æœ¬
# ä¾‹ï¼ša(1).txt / a (2).txt / a(12) (3).jpg éƒ½ä¼šè¢«åˆ é™¤
PAREN_NUM_IN_STEM = re.compile(r'\(\s*\d+\s*\)')

def iter_files(folder):
    if RECURSIVE:
        for root, _, files in os.walk(folder):
            for f in files:
                yield root, f
    else:
        for f in os.listdir(folder):
            p = os.path.join(folder, f)
            if os.path.isfile(p):
                yield folder, f

deleted, skipped = 0, 0

for root, fname in iter_files(FOLDER):
    stem, ext = os.path.splitext(fname)
    if ext == '':  # æ— æ‰©å±•åä¹ŸæŒ‰è§„åˆ™å¤„ç†
        stem = fname
    if PAREN_NUM_IN_STEM.search(stem):
        path = os.path.join(root, fname)
        try:
            if DRY_RUN:
                print(f'[é¢„æ¼”] å°†åˆ é™¤ï¼š{path}')
            else:
                os.remove(path)
                print(f'å·²åˆ é™¤ï¼š{path}')
            deleted += 1
        except Exception as e:
            print(f'åˆ é™¤å¤±è´¥ï¼š{path}ï¼ŒåŸå› ï¼š{e}')
            skipped += 1

print(f'\nå®Œæˆã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shan-chu-zhong-fu-wen-jian.html</guid><pubDate>Thu, 14 Aug 2025 14:07:26 +0000</pubDate></item><item><title>æ–‡æœ¬åˆå¹¶</title><link>https://feeday.cn/post/wen-ben-he-bing.html</link><description>##  ç‰¹æ®Šæ ¼å¼æ–‡æœ¬åˆå¹¶
```
import os
import chardet  # pip install chardet

# æŒ‡å®šç›®å½•è·¯å¾„ï¼ˆä¿®æ”¹ä¸ºä½ çš„ç›®å½•ï¼‰
directory = r'D:\txthb'  # ç¤ºä¾‹ï¼šr'D:\data\texts'

# è¾“å‡ºæ–‡ä»¶è·¯å¾„
output_file = os.path.join(directory, 'merged.txt')
error_log = os.path.join(directory, 'errors.log')

# æ‰©å±•å¸¸è§ç¼–ç åˆ—è¡¨ï¼Œæ”¯æŒæ›´å¤šï¼ˆå¦‚ç¹ä½“Big5ã€UTF-16ï¼‰
common_encodings = ['utf-8', 'gbk', 'utf-8-sig', 'gb2312', 'big5', 'utf-16', 'latin1', 'cp1252']

def read_file_with_encoding(file_path):
    # å…ˆå°è¯•æ£€æµ‹ç¼–ç 
    with open(file_path, 'rb') as f:
        raw_data = f.read()
        detected = chardet.detect(raw_data)
        encoding = detected['encoding'] if detected['encoding'] else None
    
    # å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œé€ä¸ªå°è¯•å¸¸è§ç¼–ç 
    if not encoding:
        for enc in common_encodings:
            try:
                with open(file_path, 'r', encoding=enc) as f:
                    return f.read().strip()
            except UnicodeDecodeError:
                continue
        raise ValueError(f'æ— æ³•è¯»å–æ–‡ä»¶ {file_path}ï¼Œç¼–ç ä¸æ”¯æŒã€‚</description><guid isPermaLink="true">https://feeday.cn/post/wen-ben-he-bing.html</guid><pubDate>Tue, 12 Aug 2025 10:27:27 +0000</pubDate></item><item><title>å¾®è½¯æœ¬åœ°æ–‡å­—è½¬è¯­éŸ³</title><link>https://feeday.cn/post/wei-ruan-ben-di-wen-zi-zhuan-yu-yin.html</link><description>## HTML ç‰ˆæœ¬
```
&lt;!DOCTYPE html&gt;
&lt;html lang='zh-CN'&gt;
&lt;head&gt;
    &lt;meta charset='UTF-8'&gt;
    &lt;meta name='viewport' content='width=device-width, initial-scale=1.0'&gt;
    &lt;title&gt;æ–‡æœ¬è½¬è¯­éŸ³å¹¶æ’­æ”¾&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;h1&gt;æ–‡æœ¬è½¬è¯­éŸ³å¹¶æ’­æ”¾&lt;/h1&gt;

    &lt;label for='textInput'&gt;è¯·è¾“å…¥æ–‡æœ¬ï¼š&lt;/label&gt;&lt;br&gt;
    &lt;textarea id='textInput' rows='4' cols='50'&gt;&lt;/textarea&gt;&lt;br&gt;&lt;br&gt;

    &lt;label for='filterChinese'&gt;åªæ˜¾ç¤ºä¸­æ–‡è¯­éŸ³ï¼Ÿ&lt;/label&gt;
    &lt;input type='checkbox' id='filterChinese' checked&gt;&lt;br&gt;&lt;br&gt;

    &lt;label for='voiceSelect'&gt;é€‰æ‹©è¯­éŸ³ï¼ˆéŸ³è‰²ï¼‰ï¼š&lt;/label&gt;
    &lt;select id='voiceSelect'&gt;&lt;/select&gt;&lt;br&gt;&lt;br&gt;

    &lt;button id='startButton'&gt;å¼€å§‹æœ—è¯»&lt;/button&gt;
    &lt;button id='stopButton'&gt;åœæ­¢æœ—è¯»&lt;/button&gt;

    &lt;script&gt;
        // è·å–å¯ç”¨çš„è¯­éŸ³å¹¶å¡«å……é€‰æ‹©æ¡†
        function populateVoiceList() {
            const voices = speechSynthesis.getVoices();
            const voiceSelect = document.getElementById('voiceSelect');
            const filterChinese = document.getElementById('filterChinese').checked;
            voiceSelect.innerHTML = ''; // æ¸…ç©ºç°æœ‰é€‰é¡¹

            // æ”¯æŒæ‰€æœ‰è¯­éŸ³ï¼ˆæ›´å¤šéŸ³è‰²ï¼‰ï¼Œæˆ–å¯é€‰è¿‡æ»¤ä¸­æ–‡
            let filteredVoices = voices;
            if (filterChinese) {
                filteredVoices = voices.filter(voice =&gt; voice.lang.startsWith('zh-')); // æ”¯æŒ zh-CN, zh-TW ç­‰
            }

            console.log('å¯ç”¨è¯­éŸ³åˆ—è¡¨:', filteredVoices); // è°ƒè¯•ï¼šæ‰“å°åˆ°æ§åˆ¶å°

            if (filteredVoices.length === 0) {
                // å¦‚æœæ²¡æœ‰è¯­éŸ³ï¼Œæ˜¾ç¤ºæç¤º
                const option = document.createElement('option');
                option.textContent = 'æ— å¯ç”¨è¯­éŸ³ï¼ˆè¯·å®‰è£…TTSå¼•æ“ï¼‰';
                option.disabled = true;
                voiceSelect.appendChild(option);
                alert('æœªæ£€æµ‹åˆ°ä»»ä½•å¯ç”¨è¯­éŸ³ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/wei-ruan-ben-di-wen-zi-zhuan-yu-yin.html</guid><pubDate>Tue, 12 Aug 2025 04:37:10 +0000</pubDate></item><item><title>è§†é¢‘å»¶é•¿</title><link>https://feeday.cn/post/shi-pin-yan-chang.html</link><description># è§†é¢‘å»¶é•¿

ä¸æ»¡è¶³åç§’çš„æ°´å¹³æ­£å€’æ’­æ”¾å»¶è¿Ÿåç§’ä»¥ä¸Š

```
import os, math
from moviepy.editor import VideoFileClip, concatenate_videoclips, vfx

# === é…ç½® ===
INPUT_DIR  = r'D:\\1'   # å¾…å¤„ç†è§†é¢‘ç›®å½•
OUTPUT_DIR = r'D:\2'   # è¾“å‡ºç›®å½•
TARGET_SEC = 10                      # æœ€å°‘ç›®æ ‡æ—¶é•¿ï¼ˆç§’ï¼‰
EXTS = ('.mp4', '.mov', '.avi', '.mkv', '.m4v')

os.makedirs(OUTPUT_DIR, exist_ok=True)

def build_pingpong_min_duration(clip, min_sec=10):
    '''
    æŠŠ clip åšæˆâ€œæ­£æ”¾+å€’æ”¾â€äº¤æ›¿çš„ ping-pong å¾ªç¯ï¼Œ
    ä¸€ç›´æ‹¼åˆ°æ—¶é•¿ &gt;= min_secï¼Œä¸æˆªæ–­ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shi-pin-yan-chang.html</guid><pubDate>Mon, 11 Aug 2025 04:31:45 +0000</pubDate></item><item><title>deepseek-chat-é¬¼æ•…äº‹-é›¾é’Ÿå··</title><link>https://feeday.cn/post/deepseek-chat--gui-gu-shi---wu-zhong-xiang.html</link><description>## é›¾é’Ÿå··

### æ–‡æ¡ˆ  

'å½“é’Ÿå£°æ•²å“ç¬¬åäºŒä¸‹ï¼Œä½ ä¼šå¬è§è‡ªå·±çš„å¿ƒè·³æ¶ˆå¤±ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/deepseek-chat--gui-gu-shi---wu-zhong-xiang.html</guid><pubDate>Sun, 10 Aug 2025 04:26:13 +0000</pubDate></item><item><title>æŒ‡å®šæ–‡ä»¶å¤¹é‡å‘½å</title><link>https://feeday.cn/post/zhi-ding-wen-jian-jia-zhong-ming-ming.html</link><description>æŒ‡å®šæ–‡ä»¶å¤¹åŒ…å«å­æ–‡ä»¶å¤¹é‡å‘½å
```
import os
import shutil
import uuid

def rename_image_files(directory, prefix='Real_'):
    '''
    éå†ç›®å½•åŠå­ç›®å½•ï¼Œæ‰¹é‡é‡å‘½åå›¾åƒ/è§†é¢‘æ–‡ä»¶ä¸º å‰ç¼€+ç¼–å·ï¼Œé¿å…é‡å¤ã€è¦†ç›–ã€é—æ¼ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/zhi-ding-wen-jian-jia-zhong-ming-ming.html</guid><pubDate>Fri, 08 Aug 2025 04:24:09 +0000</pubDate></item><item><title>Kontext-æç¤ºè¯</title><link>https://feeday.cn/post/Kontext--ti-shi-ci.html</link><description>

- [https://huggingface.co/spaces/kontext-community](https://huggingface.co/spaces/kontext-community/FLUX.1-Kontext-multi-image)

## è€ç…§ç‰‡ä¿®å¤
```
restore and colorize this photo. Repair the damaged white background. Maintain the consistency between the characters and the background
```

- https://zhuanlan.zhihu.com/p/1922042108895797435

éœ€æ±‚ç±»å‹ | è‹±æ–‡æ¨¡æ¿ | ä¸­æ–‡è§£æ
-- | -- | --
å¯¹è±¡ä¿®æ”¹ | 'Change [object] to [new state], keep [content to preserve] unchanged' | æ›´æ”¹ [å…·ä½“å¯¹è±¡] ä¸º [æ–°çš„çŠ¶æ€]ï¼ŒåŒæ—¶ä¿æŒ [éœ€è¦ä¿ç•™çš„å†…å®¹] ä¸å˜ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/Kontext--ti-shi-ci.html</guid><pubDate>Wed, 30 Jul 2025 10:02:57 +0000</pubDate></item><item><title>å¤šä¸ªè¡¨åˆå¹¶</title><link>https://feeday.cn/post/duo-ge-biao-he-bing.html</link><description>### å¤šå¼ æ ¼å¼ä¸€æ ·çš„è¡¨åˆå¹¶æˆä¸€ä¸ªè¡¨
```
import pandas as pd
import os

# è®¾ç½®æ–‡ä»¶å¤¹è·¯å¾„
folder_path = r'D:\hb  # æ›¿æ¢ä¸ºä½ çš„CSVæ–‡ä»¶å¤¹è·¯å¾„

# è·å–æ‰€æœ‰ CSV æ–‡ä»¶è·¯å¾„
csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]

# åˆå¹¶æ‰€æœ‰ CSV æ–‡ä»¶
df_list = [pd.read_csv(os.path.join(folder_path, f)) for f in csv_files]
combined_df = pd.concat(df_list, ignore_index=True)

# ä¿å­˜ä¸ºä¸€ä¸ªæ–°æ–‡ä»¶
combined_df.to_csv(r'D:\hb.csv', index=False)

```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/duo-ge-biao-he-bing.html</guid><pubDate>Mon, 28 Jul 2025 05:05:08 +0000</pubDate></item><item><title>æ–‡æœ¬è¡Œè½¬è¡¨åˆ—</title><link>https://feeday.cn/post/wen-ben-xing-zhuan-biao-lie.html</link><description>
### è¿è¡Œè„šæœ¬
```
import sys
import subprocess
import os
import re

# è‡ªåŠ¨å®‰è£…åŒ…çš„å‡½æ•°
def install_package(package):
    try:
        __import__(package)
    except ImportError:
        print(f'ç¼ºå°‘åŒ… {package}ï¼Œæ­£åœ¨å®‰è£…...')
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])
        print(f'{package} å®‰è£…å®Œæˆã€‚</description><guid isPermaLink="true">https://feeday.cn/post/wen-ben-xing-zhuan-biao-lie.html</guid><pubDate>Thu, 24 Jul 2025 14:56:23 +0000</pubDate></item><item><title>è¯­è¨€æ¨¡å‹-API-æ‰¹é‡ç”Ÿæˆæ–‡æœ¬</title><link>https://feeday.cn/post/yu-yan-mo-xing--API--pi-liang-sheng-cheng-wen-ben.html</link><description>æ–‡æœ¬æ¨¡å‹æ‰¹é‡ç”Ÿæˆæ–‡æœ¬æµ‹è¯•

## ChatGPT 

ç¬¬ä¸‰æ–¹ä»£ç†æ¥å£

-  [https://openkey.cloud](https://openkey.cloud/register?aff=22CVF)

### æ‰§è¡Œè„šæœ¬
```
from openai import OpenAI
import time
import csv
import os
from datetime import datetime

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(
    api_key='sk-x',
    base_url='https://openkey.cloud/v1'
)

primary_classes = [
    'æ¡ˆä»¶æ¡ˆä¾‹', 'åšå®¢æ–‡ç« ', 'ä¸ªäººæ—¥è®°', 'è§‚ç‚¹', 'å¹¿å‘Šæ–‡æ¡ˆ', 'æŠ€æœ¯æ–‡æ¡£',
    'è¯„è®º', 'æ•£æ–‡', 'ç¤¾äº¤åª’ä½“å¸–å­', 'è¯—æ­Œ', 'å°è¯´ç‰‡æ®µ', 'æ–°é—»æŠ¥é“', 'å­¦æœ¯è®ºæ–‡æ‘˜è¦'
]

secondary_classes = [
    'AI', 'åŠ¨ç‰©', 'æƒ…æ„Ÿ', 'å…¬ç›Š', 'è´­ç‰©', 'å¤ä»£æ–‡æ˜', 'äº¤é€š', 'æ•™è‚²', 'è¿‘ä»£æˆ˜äº‰', 'ç»æµ',
    'ç§‘å¹»', 'ç§‘æŠ€', 'ç§‘æ™®', 'å†å²', 'æ—…è¡Œ', 'ç¾é£Ÿ', 'æ¯å©´', 'å¥‡å¹»', 'æ°”å€™å˜åŒ–', 'ä¸‰å†œ',
    'ç¤¾ä¼šé—®é¢˜', 'æ‘„å½±', 'ç”Ÿæ´»', 'æ—¶å°š', 'æ—¶æ”¿', 'ä½“è‚²', 'æ–‡åŒ–', 'æ­¦å™¨', 'æ ¡å›­', 'åŒ»ç–—',
    'è‰ºæœ¯', 'éŸ³ä¹', 'å½±è§†', 'æ¸¸æˆ', 'å¨±ä¹', 'è‚²å„¿', 'èŒåœº', 'æ¤ç‰©', 'å•†ä¸š'
]

styles = ['æ­£å¼', 'å™äº‹', 'æƒ…æ„ŸåŒ–', 'ç§‘æ™®']

category_map = {
    'æ¡ˆä»¶æ¡ˆä¾‹': 'Case Study',
    'åšå®¢æ–‡ç« ': 'Blog Article',
    'ä¸ªäººæ—¥è®°': 'Personal Diary',
    'è§‚ç‚¹': 'Opinion',
    'å¹¿å‘Šæ–‡æ¡ˆ': 'Advertising Copy',
    'æŠ€æœ¯æ–‡æ¡£': 'Technical Document',
    'è¯„è®º': 'Review',
    'æ•£æ–‡': 'Essay',
    'ç¤¾äº¤åª’ä½“å¸–å­': 'Social Media Post',
    'è¯—æ­Œ': 'Poetry',
    'å°è¯´ç‰‡æ®µ': 'Fiction Excerpt',
    'æ–°é—»æŠ¥é“': 'News Report',
    'å­¦æœ¯è®ºæ–‡æ‘˜è¦': 'Academic Abstract',
    'AI': 'Artificial Intelligence',
    'åŠ¨ç‰©': 'Animals',
    'æƒ…æ„Ÿ': 'Emotion',
    'å…¬ç›Š': 'Public Welfare',
    'è´­ç‰©': 'Shopping',
    'å¤ä»£æ–‡æ˜': 'Ancient Civilization',
    'äº¤é€š': 'Transportation',
    'æ•™è‚²': 'Education',
    'è¿‘ä»£æˆ˜äº‰': 'Modern War',
    'ç»æµ': 'Economics',
    'ç§‘å¹»': 'Science Fiction',
    'ç§‘æŠ€': 'Technology',
    'ç§‘æ™®': 'Popular Science',
    'å†å²': 'History',
    'æ—…è¡Œ': 'Travel',
    'ç¾é£Ÿ': 'Cuisine',
    'æ¯å©´': 'Mother and Baby',
    'å¥‡å¹»': 'Fantasy',
    'æ°”å€™å˜åŒ–': 'Climate Change',
    'ä¸‰å†œ': 'Agriculture and Rural Affairs',
    'ç¤¾ä¼šé—®é¢˜': 'Social Issues',
    'æ‘„å½±': 'Photography',
    'ç”Ÿæ´»': 'Lifestyle',
    'æ—¶å°š': 'Fashion',
    'æ—¶æ”¿': 'Current Politics',
    'ä½“è‚²': 'Sports',
    'æ–‡åŒ–': 'Culture',
    'æ­¦å™¨': 'Weapons',
    'æ ¡å›­': 'Campus',
    'åŒ»ç–—': 'Medical',
    'è‰ºæœ¯': 'Art',
    'éŸ³ä¹': 'Music',
    'å½±è§†': 'Film and TV',
    'æ¸¸æˆ': 'Gaming',
    'å¨±ä¹': 'Entertainment',
    'è‚²å„¿': 'Parenting',
    'èŒåœº': 'Workplace',
    'æ¤ç‰©': 'Plants',
    'å•†ä¸š': 'Business',
    'æ­£å¼': 'Formal',
    'å™äº‹': 'Narrative',
    'æƒ…æ„ŸåŒ–': 'Emotional',
    'ç§‘æ™®': 'Popular Science'
}

def char_count(text: str) -&gt; int:
    return len(text)

def generate_text(primary, secondary, style, max_retries=3):
    primary_en = category_map.get(primary, primary)
    secondary_en = category_map.get(secondary, secondary)
    style_en = category_map.get(style, style)

    prompt = (
        f'Please write a coherent, well-structured English text with at least 250 characters and preferably no more than 350 characters about the following:\n'
        f'Primary category: {primary_en}\n'
        f'Secondary category: {secondary_en}\n'
        f'Writing style: {style_en}\n'
        f'Important: The entire text must be in English without any Chinese characters or words.'
    )
    text = ''
    for attempt in range(1, max_retries + 1):
        try:
            response = client.chat.completions.create(
                model='gpt-4o-mini',
                messages=[{'role': 'user', 'content': prompt}],
                temperature=0.7,
                max_tokens=900
            )
            text = response.choices[0].message.content.strip()
            char_num = char_count(text)
            if char_num &gt;= 250:
                return text
            else:
                print(f'Retry {attempt} for {primary}-{secondary}-{style}, char count {char_num} &lt; 250')
                time.sleep(1)
        except Exception as e:
            print(f'Error for {primary}-{secondary}-{style}: {e}')
            time.sleep(2)
    print(f'Max retries reached for {primary}-{secondary}-{style}, returning last result')
    return text

def write_to_csv_with_timestamp(base_name, rows, batch_size, output_dir='D:/data/output'):
    os.makedirs(output_dir, exist_ok=True)
    now_str = datetime.now().strftime('%Y%m%d%H%M')
    filename = f'{base_name}_{now_str}_{batch_size}.csv'
    full_path = os.path.join(output_dir, filename)
    with open(full_path, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow(['ç¼–å·', 'ä¸€çº§ç±»', 'äºŒçº§ç±»', 'é£æ ¼', 'å†…å®¹', 'å­—ç¬¦æ•°'])
        writer.writerows(rows)
    print(f'Saved batch of {len(rows)} records to {full_path}')

def main():
    total_tasks = len(primary_classes) * len(secondary_classes) * len(styles)
    task_counter = 0
    batch_size = 5  # ç”Ÿæˆ5æ¡ä¿å­˜æˆè¡¨
    buffer = []
    base_name = 'generated_texts'
    output_dir = r'C:\test'  # ä½ éœ€è¦çš„è¾“å‡ºç›®å½•ï¼Œè¯·ä¿®æ”¹ä¸ºä½ æƒ³è¦çš„è·¯å¾„

    for primary in primary_classes:
        for secondary in secondary_classes:
            for style in styles:
                task_counter += 1
                print(f'\n[{task_counter}/{total_tasks}] Generating: {primary} - {secondary} - {style}\n')
                content = generate_text(primary, secondary, style)
                char_num = char_count(content)
                print(f'Content ({char_num} chars):\n')
                print(content)
                print('\n' + '='*80 + '\n')

                buffer.append([task_counter, primary, secondary, style, content, char_num])

                if len(buffer) &gt;= batch_size:
                    write_to_csv_with_timestamp(base_name, buffer, batch_size, output_dir=output_dir)
                    buffer.clear()

                time.sleep(1)  # é™æµé˜²å°ç¦

    if buffer:
        write_to_csv_with_timestamp(base_name, buffer, len(buffer), output_dir=output_dir)

    print('All done!')

if __name__ == '__main__':
    main()
```
### è¾“å‡ºç»“æœ
```
[354/2028] Generating: ä¸ªäººæ—¥è®° - ç§‘å¹» - å™äº‹
Generated chars: 400
Full content:
October 12, 2147

Today, I stumbled upon an ancient device in the ruins of an old libraryâ€”an old smartphone. Its screen flickered to life, revealing images of a world long gone. I felt a surge of nostalgia for a time when humans thrived on connection, not just data. As I scrolled through its apps, I wondered what stories lay hidden in its memory, waiting to bridge the gap between past and present.
```

## DeepSeek
- [https://platform.deepseek.com/api_keys](https://platform.deepseek.com/api_keys)
### è¿è¡Œè„šæœ¬
```
from openai import OpenAI
import time
import csv
import os
from datetime import datetime

# åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œæ›¿æ¢æˆ DeepSeek çš„ base_url å’Œ api_key
client = OpenAI(
    api_key='sk-x',  # è¿™é‡Œæ¢æˆä½ åœ¨ DeepSeek ç”³è¯·çš„ API Key
    base_url='https://api.deepseek.com'    # DeepSeek API åœ°å€ï¼Œå¸¦/v1ä¹Ÿå¯ä»¥
)

primary_classes = [
    'æ¡ˆä»¶æ¡ˆä¾‹', 'åšå®¢æ–‡ç« ', 'ä¸ªäººæ—¥è®°', 'è§‚ç‚¹', 'å¹¿å‘Šæ–‡æ¡ˆ', 'æŠ€æœ¯æ–‡æ¡£',
    'è¯„è®º', 'æ•£æ–‡', 'ç¤¾äº¤åª’ä½“å¸–å­', 'è¯—æ­Œ', 'å°è¯´ç‰‡æ®µ', 'æ–°é—»æŠ¥é“', 'å­¦æœ¯è®ºæ–‡æ‘˜è¦'
]

secondary_classes = [
    'AI', 'åŠ¨ç‰©', 'æƒ…æ„Ÿ', 'å…¬ç›Š', 'è´­ç‰©', 'å¤ä»£æ–‡æ˜', 'äº¤é€š', 'æ•™è‚²', 'è¿‘ä»£æˆ˜äº‰', 'ç»æµ',
    'ç§‘å¹»', 'ç§‘æŠ€', 'ç§‘æ™®', 'å†å²', 'æ—…è¡Œ', 'ç¾é£Ÿ', 'æ¯å©´', 'å¥‡å¹»', 'æ°”å€™å˜åŒ–', 'ä¸‰å†œ',
    'ç¤¾ä¼šé—®é¢˜', 'æ‘„å½±', 'ç”Ÿæ´»', 'æ—¶å°š', 'æ—¶æ”¿', 'ä½“è‚²', 'æ–‡åŒ–', 'æ­¦å™¨', 'æ ¡å›­', 'åŒ»ç–—',
    'è‰ºæœ¯', 'éŸ³ä¹', 'å½±è§†', 'æ¸¸æˆ', 'å¨±ä¹', 'è‚²å„¿', 'èŒåœº', 'æ¤ç‰©', 'å•†ä¸š'
]

styles = ['æ­£å¼', 'å™äº‹', 'æƒ…æ„ŸåŒ–', 'ç§‘æ™®']

def generate_text(primary: str, secondary: str, style: str, max_retries=3) -&gt; str:
    prompt = (
        f'Please write an English text about the following topic.\n'
        f'The text must be coherent and well-structured,\n'
        f'with at least 200 characters. Avoid making the text too long.\n\n'
        f'Primary category: {primary}\n'
        f'Secondary category: {secondary}\n'
        f'Writing style: {style}'
    )
    text = ''
    for attempt in range(1, max_retries + 1):
        try:
            response = client.chat.completions.create(
                model='deepseek-chat',
                messages=[{'role': 'user', 'content': prompt}],
                temperature=0.7,
                max_tokens=500  # å…è®¸ç¨é•¿æ–‡æœ¬ï¼Œæ¨¡å‹è‡ªåŠ¨æ§åˆ¶é•¿åº¦
            )
            text = response.choices[0].message.content.strip()
            length = len(text)
            if length &gt;= 200:
                return text.replace('\n', ' ')
            else:
                print(f'Retry {attempt} for {primary} - {secondary} - {style}: char count {length} &lt; 200')
                time.sleep(1)
        except Exception as e:
            print(f'Error on {primary} - {secondary} - {style}: {e}')
            time.sleep(2)

    print(f'Max retries reached for {primary} - {secondary} - {style}. Returning last result.')
    if text:
        return text.replace('\n', ' ')
    return ''

def save_batch_to_csv(rows, batch_num, base_name='deepseek_output', output_dir='output'):
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
    filename = f'{base_name}_{timestamp}_batch{batch_num}.csv'
    filepath = os.path.join(output_dir, filename)
    with open(filepath, mode='w', encoding='utf-8-sig', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['ç¼–å·', 'ä¸€çº§ç±»', 'äºŒçº§ç±»', 'é£æ ¼', 'å†…å®¹', 'å­—ç¬¦æ•°'])
        writer.writerows(rows)
    print(f'Saved batch {batch_num} with {len(rows)} records to {filepath}')

def main():
    total_tasks = len(primary_classes) * len(secondary_classes) * len(styles)
    task_counter = 0
    batch_size = 5  # ç”Ÿæˆ5æ¡ä¿å­˜æˆè¡¨
    batch_data = []
    batch_number = 1
    base_name = 'deepseek_output'
    output_dir = r'c:\test'  # ä¿®æ”¹æˆä½ æƒ³ä¿å­˜çš„è·¯å¾„

    for primary in primary_classes:
        for secondary in secondary_classes:
            for style in styles:
                task_counter += 1
                print(f'\n[{task_counter}/{total_tasks}] Generating: {primary} - {secondary} - {style}\n')
                content = generate_text(primary, secondary, style)
                length = len(content)
                print(f'Content ({length} characters):\n')
                print(content)
                print('\n' + '='*100 + '\n')

                batch_data.append([task_counter, primary, secondary, style, content, length])

                if len(batch_data) &gt;= batch_size:
                    save_batch_to_csv(batch_data, batch_number, base_name, output_dir)
                    batch_data.clear()
                    batch_number += 1

                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«è¢«é™æµ

    if batch_data:
        save_batch_to_csv(batch_data, batch_number, base_name, output_dir)

    print('All tasks completed.')

if __name__ == '__main__':
    main()
```
### è¾“å‡ºç»“æœ
```
[15/2028] Generating: æ¡ˆä»¶æ¡ˆä¾‹ - å…¬ç›Š - æƒ…æ„ŸåŒ–

Content (827 characters):

**A Beacon of Hope: The Power of Compassion in Legal Cases**    In the midst of cold courtrooms and rigid laws, some cases shine as reminders of humanityâ€™s warmth. Take the story of an elderly woman evicted unfairlyâ€”her plight moved strangers to crowdfund her legal fees. Or the pro bono lawyers who fought for a childâ€™s right to education against all odds. These stories arenâ€™t just about justice; theyâ€™re about hearts uniting to lift others up.    Every such case whispers a truth: the law is stronger when wrapped in kindness. Behind every docket number is a life, and behind every verdict, a chance to heal. Letâ€™s celebrate these unsung heroesâ€”the donors, volunteers, and advocatesâ€”who turn legal battles into triumphs of empathy. Because justice, when paired with love, doesnâ€™t just winâ€”it transforms.    (Characters: 598)
```
## Kimi 

-  [https://platform.moonshot.cn/console/api-keys](https://platform.moonshot.cn/console/api-keys)

### æ‰§è¡Œè„šæœ¬
```
from openai import OpenAI
import time
import csv
import os
from datetime import datetime

# === æ¨¡å‹é€‰æ‹© ===
USE_MODEL = 'moonshot'

# === åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆMoonshot ä¸­æ–‡ï¼‰===
client = OpenAI(
    api_key='sk-xxx',  # â† æ›¿æ¢ä¸ºä½ çš„ API Key
    base_url='https://api.moonshot.cn/v1'
)



model_name = 'kimi-k2-0711-preview'
system_prompt = (
    'ä½ æ˜¯ Kimiï¼Œç”± Moonshot AI æä¾›çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/yu-yan-mo-xing--API--pi-liang-sheng-cheng-wen-ben.html</guid><pubDate>Thu, 24 Jul 2025 14:11:48 +0000</pubDate></item><item><title>ç­›å‡ºæ–‡ä»¶æŒ‡å®šæ¯”ä¾‹çš„æ–‡ä»¶</title><link>https://feeday.cn/post/shai-chu-wen-jian-zhi-ding-bi-li-de-wen-jian.html</link><description>ç­›å‡ºæ–‡ä»¶æŒ‡å®šæ¯”ä¾‹çš„æ–‡ä»¶
```
import os
import shutil
import random

# è®¾ç½®æºç›®å½•å’Œç›®æ ‡ç›®å½•
source_dir = r'G:\trian'
target_dir = r'G:\test'
move_percent = 10  # ç™¾åˆ†æ¯”

# éå†ä¸€çº§å­æ–‡ä»¶å¤¹
for subfolder in os.listdir(source_dir):
    subfolder_path = os.path.join(source_dir, subfolder)
    if not os.path.isdir(subfolder_path):
        continue  # è·³è¿‡éæ–‡ä»¶å¤¹é¡¹

    # æ”¶é›†è¯¥å­æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰æ–‡ä»¶ï¼ˆé€’å½’ï¼‰
    all_files = []
    for root, _, files in os.walk(subfolder_path):
        for file in files:
            full_path = os.path.join(root, file)
            all_files.append(full_path)

    # éšæœºé€‰å–ç™¾åˆ†æ¯”æ–‡ä»¶
    total = len(all_files)
    if total == 0:
        continue

    move_count = max(1, int(total * move_percent / 100))
    selected_files = random.sample(all_files, move_count)

    # æ‰§è¡Œç§»åŠ¨
    for file_path in selected_files:
        rel_path = os.path.relpath(file_path, source_dir)
        dest_path = os.path.join(target_dir, rel_path)
        os.makedirs(os.path.dirname(dest_path), exist_ok=True)
        shutil.move(file_path, dest_path)
        print(f'Moved: {file_path} â†’ {dest_path}')

print(f'\nâœ… æ¯ä¸ªå­æ–‡ä»¶å¤¹å·²éšæœºç§»åŠ¨çº¦ {move_percent}% æ–‡ä»¶ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shai-chu-wen-jian-zhi-ding-bi-li-de-wen-jian.html</guid><pubDate>Wed, 23 Jul 2025 04:51:37 +0000</pubDate></item><item><title>è§†é¢‘æå–å›¾åƒ</title><link>https://feeday.cn/post/shi-pin-ti-qu-tu-xiang.html</link><description>è§†é¢‘æå–å›¾åƒ
```
import cv2
import os

def extract_frames(video_path, output_folder):
    # è·å–è§†é¢‘æ–‡ä»¶åå¹¶ç”¨ä½œè¾“å‡ºæ–‡ä»¶å¤¹çš„åç§°ï¼ˆå»æ‰æ‰©å±•åï¼‰
    video_name = os.path.splitext(os.path.basename(video_path))[0]
    video_output_folder = os.path.join(output_folder, video_name)
    
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(video_output_folder, exist_ok=True)

    # æ‰“å¼€è§†é¢‘æ–‡ä»¶
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f'æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶ï¼š{video_path}')
        return

    # è·å–è§†é¢‘çš„å¸§ç‡ï¼ˆFPSï¼‰
    fps = cap.get(cv2.CAP_PROP_FPS)
    print(f'è§†é¢‘å¸§ç‡ï¼š{fps} FPS')

    # è·å–è§†é¢‘çš„æ€»å¸§æ•°
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    print(f'è§†é¢‘æ€»å¸§æ•°ï¼š{total_frames}')

    # éå†è§†é¢‘ä¸­çš„æ¯ä¸€å¸§
    for frame_num in range(total_frames):
        ret, frame = cap.read()
        if not ret:
            print(f'æ— æ³•è¯»å–ç¬¬ {frame_num} å¸§')
            break

        # æ¯ç§’æå–ä¸€å¸§
        if frame_num % int(fps) == 0:
            # è·å–å½“å‰å¸§çš„æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
            timestamp = frame_num // int(fps)
            # æ„é€ è¾“å‡ºå›¾åƒçš„æ–‡ä»¶è·¯å¾„
            output_path = os.path.join(video_output_folder, f'frame_{timestamp:04d}.jpg')
            # ä¿å­˜å½“å‰å¸§ä¸ºå›¾åƒæ–‡ä»¶
            if frame is not None:
                cv2.imwrite(output_path, frame)
                print(f'å·²ä¿å­˜ï¼š{output_path}')
            else:
                print(f'ç¬¬ {timestamp} ç§’å›¾åƒä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shi-pin-ti-qu-tu-xiang.html</guid><pubDate>Wed, 23 Jul 2025 04:50:00 +0000</pubDate></item><item><title>ç­›æŸ¥é‡å¤æˆ–ç±»ä¼¼å›¾åƒ</title><link>https://feeday.cn/post/shai-cha-zhong-fu-huo-lei-si-tu-xiang.html</link><description>ç­›æŸ¥é‡å¤æˆ–ç±»ä¼¼å›¾åƒ
```
import subprocess
import sys
import os
import cv2
import numpy as np
from keras.applications.resnet50 import ResNet50, preprocess_input
from sklearn.metrics.pairwise import cosine_similarity  # ç”¨äºä½™å¼¦ç›¸ä¼¼åº¦

# pip å®‰è£… scikit-learn
def install_package(package):
    try:
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])
        print(f'{package} å®‰è£…æˆåŠŸï¼')
    except subprocess.CalledProcessError as e:
        print(f'å®‰è£…å¤±è´¥: {e}')

# ç¡®ä¿å®‰è£… scikit-learn
install_package('scikit-learn')

# æå–å›¾ç‰‡ç‰¹å¾
def extract_image_features(image_path):
    if not os.path.exists(image_path):  # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        print(f'æ–‡ä»¶ä¸å­˜åœ¨: {image_path}')
        return None
    
    image = cv2.imread(image_path)  # è¯»å–å›¾ç‰‡
    if image is None:  # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦åŠ è½½æˆåŠŸ
        print(f'æ— æ³•è¯»å–å›¾ç‰‡: {image_path}')
        return None  # å¦‚æœè¯»å–å¤±è´¥ï¼Œè¿”å›None
    image = cv2.resize(image, (256, 256))  # ç¼©æ”¾å›¾ç‰‡åˆ°ç»Ÿä¸€å°ºå¯¸
    image = image[16:240, 16:240]  # è£å‰ªä¸­é—´åŒºåŸŸ(224x224)
    
    image = np.expand_dims(image, axis=0)  # æ‰©å±•ç»´åº¦ä»¥åŒ¹é…æ¨¡å‹è¾“å…¥è¦æ±‚
    image = preprocess_input(image)  # é¢„å¤„ç†å›¾ç‰‡
    
    features = model.predict(image)  # æå–ç‰¹å¾å‘é‡
    features /= np.linalg.norm(features)  # å½’ä¸€åŒ–ç‰¹å¾å‘é‡
    
    print(f'ç‰¹å¾å‘é‡: {features.flatten()}')  # æ‰“å°ç‰¹å¾å‘é‡ï¼Œçœ‹çœ‹æ˜¯å¦æœ‰å·®å¼‚
    return features.flatten()  # å¹³é“ºç‰¹å¾å‘é‡

# ç§»åŠ¨é‡å¤å›¾ç‰‡åˆ°æŒ‡å®šæ–‡ä»¶å¤¹
def move_duplicate_images(directory, output_directory, use_cosine_similarity=True):
    current_dir = directory  # ä½¿ç”¨ä¼ å…¥çš„ç›®å½•è·¯å¾„
    files = [f for f in os.listdir(current_dir) if os.path.isfile(os.path.join(current_dir, f))]  # è·å–ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
    
    image_features = {}
    moved_count = 0  # è®°å½•ç§»åŠ¨çš„å›¾ç‰‡æ•°é‡
    duplicate_pairs = []  # ç”¨äºä¿å­˜é‡å¤å›¾ç‰‡çš„æ–‡ä»¶åå¯¹

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    if not os.path.exists(output_directory):  # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
        os.makedirs(output_directory)

    for file_name in files:
        if file_name.endswith('.jpg') or file_name.endswith('.png'):  # ç­›é€‰å‡ºå›¾ç‰‡æ–‡ä»¶
            file_path = os.path.join(current_dir, file_name)
            image_feature = extract_image_features(file_path)

            if image_feature is None:  # å¦‚æœè¯»å–å¤±è´¥ï¼Œè·³è¿‡æ­¤æ–‡ä»¶
                continue

            is_duplicate = False
            for existing_path, existing_feature in image_features.items():
                if use_cosine_similarity:
                    # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ç›¸ä¼¼åº¦
                    similarity = cosine_similarity([existing_feature], [image_feature])[0][0]
                    print(f'è®¡ç®—ç›¸ä¼¼åº¦: {similarity}')  # æ‰“å°è®¡ç®—å‡ºçš„ç›¸ä¼¼åº¦

                    if similarity &gt; 0.8:  # è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œå€¼è¶Šæ¥è¿‘1è¯´æ˜è¶Šç›¸ä¼¼
                        is_duplicate = True
                        print(f'ç§»åŠ¨é‡å¤å›¾ç‰‡: {file_path}')
                        # ç§»åŠ¨æ–‡ä»¶åˆ°æŒ‡å®šæ–‡ä»¶å¤¹
                        new_path = os.path.join(output_directory, file_name)
                        os.rename(file_path, new_path)  # ç§»åŠ¨æ–‡ä»¶
                        moved_count += 1
                        # è®°å½•é‡å¤çš„æ–‡ä»¶åå¯¹ (å½“å‰æ–‡ä»¶åå’Œå·²æœ‰æ–‡ä»¶å)
                        duplicate_pairs.append((file_name, os.path.basename(existing_path)))
                        break
                else:
                    # ä½¿ç”¨æ¬§æ°è·ç¦»è®¡ç®—ç›¸ä¼¼åº¦
                    distance = np.linalg.norm(existing_feature - image_feature)  # è®¡ç®—æ¬§æ°è·ç¦»
                    print(f'è®¡ç®—è·ç¦»: {distance}')  # æ‰“å°è®¡ç®—å‡ºçš„æ¬§æ°è·ç¦»
                    if distance &lt; 0.6:  # åˆ é™¤ç±»ä¼¼å›¾åƒ 0.6  åˆ é™¤é‡å¤å›¾åƒ 0.1
                        is_duplicate = True
                        print(f'ç§»åŠ¨é‡å¤å›¾ç‰‡: {file_path}')
                        # ç§»åŠ¨æ–‡ä»¶åˆ°æŒ‡å®šæ–‡ä»¶å¤¹
                        new_path = os.path.join(output_directory, file_name)
                        os.rename(file_path, new_path)  # ç§»åŠ¨æ–‡ä»¶
                        moved_count += 1
                        # è®°å½•é‡å¤çš„æ–‡ä»¶åå¯¹ (å½“å‰æ–‡ä»¶åå’Œå·²æœ‰æ–‡ä»¶å)
                        duplicate_pairs.append((file_name, os.path.basename(existing_path)))
                        break

            if not is_duplicate:
                image_features[file_path] = image_feature

    # å°†é‡å¤å›¾ç‰‡æ–‡ä»¶åå¯¹ä¿å­˜åˆ°txtæ–‡ä»¶
    output_file = os.path.join(output_directory, 'duplicate_images.txt')  # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„
    if duplicate_pairs:
        with open(output_file, 'w') as f:
            for file1, file2 in duplicate_pairs:
                f.write(f'{file1} ä¸ {file2} é‡å¤æˆ–ç±»ä¼¼\n')

    print('å·²ç§»åŠ¨ {} å¼ é‡å¤å›¾ç‰‡'.format(moved_count))

# åŠ è½½é¢„è®­ç»ƒçš„ResNet50æ¨¡å‹
model = ResNet50(weights='imagenet', include_top=False, pooling='avg')

# æŒ‡å®šç›®å½•è·¯å¾„ï¼Œè®¾ç½®æ˜¯å¦ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
input_directory = r'D:\test\img'  # å›¾ç‰‡æ‰€åœ¨æ–‡ä»¶å¤¹
output_directory = r'D:\test\img2'  # è‡ªå®šä¹‰ä¿å­˜é‡å¤å›¾ç‰‡çš„æ–‡ä»¶å¤¹

move_duplicate_images(input_directory, output_directory, use_cosine_similarity=False)  # è®¾ç½®ä¸ºTrueä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦åˆ¤æ–­ä¸¤ä¸ªå›¾ç‰‡çš„ç‰¹å¾æ–¹å‘æ˜¯å¦ç›¸ä¼¼ï¼Œè®¾ç½®ä¸ºFalseç§»é™¤é‡å¤å›¾åƒ
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shai-cha-zhong-fu-huo-lei-si-tu-xiang.html</guid><pubDate>Wed, 23 Jul 2025 04:47:45 +0000</pubDate></item><item><title>å›¾åƒç›´æ–¹å›¾åœ¨çº¿è°ƒèŠ‚</title><link>https://feeday.cn/post/tu-xiang-zhi-fang-tu-zai-xian-diao-jie.html</link><description>```
&lt;!DOCTYPE html&gt;
&lt;html lang='zh-CN'&gt;
&lt;head&gt;
&lt;meta charset='UTF-8'&gt;
&lt;title&gt;åœ¨çº¿å›¾åƒç›´æ–¹å›¾ä¸è°ƒæ•´&lt;/title&gt;
&lt;style&gt;
body { font-family: sans-serif; padding: 20px; max-width: 1000px; margin: auto; }
#controls { display: grid; grid-template-columns: repeat(2, 1fr); gap: 10px; margin-bottom: 20px; }
.control-group { display: flex; align-items: center; }
.control-group label { width: 80px; }
.control-group input[type=range] { flex: 1; margin: 0 10px; }
.control-group input[type=number] { width: 60px; }
canvas { border: 1px solid #ccc; display: block; margin-bottom: 20px; }
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h2&gt;åœ¨çº¿å›¾åƒç›´æ–¹å›¾ä¸è°ƒæ•´&lt;/h2&gt;
&lt;input type='file' id='fileInput' accept='image/*'&gt;
&lt;div id='controls'&gt;
&lt;div class='control-group'&gt;
&lt;label for='exposureRange'&gt;æ›å…‰&lt;/label&gt;
&lt;input type='range' id='exposureRange' min='-2' max='2' step='0.1' value='0'&gt;
&lt;input type='number' id='exposureNumber' min='-2' max='2' step='0.1' value='0'&gt;
&lt;/div&gt;
&lt;div class='control-group'&gt;
&lt;label for='contrastRange'&gt;å¯¹æ¯”åº¦&lt;/label&gt;
&lt;input type='range' id='contrastRange' min='-1' max='1' step='0.05' value='0'&gt;
&lt;input type='number' id='contrastNumber' min='-1' max='1' step='0.05' value='0'&gt;
&lt;/div&gt;
&lt;div class='control-group'&gt;
&lt;label for='highlightsRange'&gt;é«˜å…‰&lt;/label&gt;
&lt;input type='range' id='highlightsRange' min='-1' max='1' step='0.05' value='0'&gt;
&lt;input type='number' id='highlightsNumber' min='-1' max='1' step='0.05' value='0'&gt;
&lt;/div&gt;
&lt;div class='control-group'&gt;
&lt;label for='shadowsRange'&gt;é˜´å½±&lt;/label&gt;
&lt;input type='range' id='shadowsRange' min='-1' max='1' step='0.05' value='0'&gt;
&lt;input type='number' id='shadowsNumber' min='-1' max='1' step='0.05' value='0'&gt;
&lt;/div&gt;
&lt;div class='control-group'&gt;
&lt;label for='whitesRange'&gt;ç™½è‰²&lt;/label&gt;
&lt;input type='range' id='whitesRange' min='-1' max='1' step='0.05' value='0'&gt;
&lt;input type='number' id='whitesNumber' min='-1' max='1' step='0.05' value='0'&gt;
&lt;/div&gt;
&lt;div class='control-group'&gt;
&lt;label for='blacksRange'&gt;é»‘è‰²&lt;/label&gt;
&lt;input type='range' id='blacksRange' min='-1' max='1' step='0.05' value='0'&gt;
&lt;input type='number' id='blacksNumber' min='-1' max='1' step='0.05' value='0'&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;canvas id='previewCanvas' width='800' height='600'&gt;&lt;/canvas&gt;
&lt;canvas id='histCanvas' width='800' height='200'&gt;&lt;/canvas&gt;

&lt;!-- å¼•å…¥ Chart.js --&gt;
&lt;script src='https://cdn.jsdelivr.net/npm/chart.js'&gt;&lt;/script&gt;
&lt;script&gt;
let originalImageData = null;
const previewCanvas = document.getElementById('previewCanvas');
const previewCtx = previewCanvas.getContext('2d');
const histCanvas = document.getElementById('histCanvas');
const histCtx = histCanvas.getContext('2d');
let histChart = null;

// è¯»å–æ§ä»¶å…ƒç´ 
const controls = ['exposure','contrast','highlights','shadows','whites','blacks'];
const state = {};
controls.forEach(name =&gt; {
state[name] = 0;
const rangeEl = document.getElementById(name + 'Range');
const numEl = document.getElementById(name + 'Number');
// åŒæ­¥æ»‘å—å’Œæ•°å­—
rangeEl.addEventListener('input', () =&gt; { numEl.value = rangeEl.value; updateState(); });
numEl.addEventListener('input', () =&gt; { rangeEl.value = numEl.value; updateState(); });
});

document.getElementById('fileInput').addEventListener('change', (e) =&gt; {
const file = e.target.files[0];
if (!file) return;
const img = new Image();
img.onload = () =&gt; {
// è°ƒæ•´ç”»å¸ƒå¤§å°
previewCanvas.width = img.width;
previewCanvas.height = img.height;
previewCtx.drawImage(img, 0, 0);
originalImageData = previewCtx.getImageData(0, 0, img.width, img.height);
applyAdjustments();
};
img.src = URL.createObjectURL(file);
});

function updateState() {
controls.forEach(name =&gt; {
state[name] = parseFloat(document.getElementById(name + 'Number').value);
});
applyAdjustments();
}

function applyAdjustments() {
if (!originalImageData) return;
const imgData = new ImageData(
new Uint8ClampedArray(originalImageData.data),
originalImageData.width,
originalImageData.height
);
const data = imgData.data;
const {exposure, contrast, highlights, shadows, whites, blacks} = state;
for (let i = 0; i &lt; data.length; i += 4) {
let r = data[i] / 255;
let g = data[i+1] / 255;
let b = data[i+2] / 255;
// äº®åº¦
const lum = 0.2126*r + 0.7152*g + 0.0722*b;
// æ›å…‰ï¼š2^EV
const evFactor = Math.pow(2, exposure);
r *= evFactor; g *= evFactor; b *= evFactor;
// å¯¹æ¯”åº¦
const cFactor = contrast + 1;
r = (r - 0.5) * cFactor + 0.5;
g = (g - 0.5) * cFactor + 0.5;
b = (b - 0.5) * cFactor + 0.5;
// é«˜å…‰/é˜´å½±
if (lum &gt; 0.5) {
const factor = (lum - 0.5) * 2;
r += highlights * factor;
g += highlights * factor;
b += highlights * factor;
} else {
const factor = (0.5 - lum) * 2;
r += shadows * factor;
g += shadows * factor;
b += shadows * factor;
}
// ç™½è‰²/é»‘è‰²å‰ªåˆ‡
if (lum &gt; 0.8) {
const factor = (lum - 0.8) * 5;
r += whites * factor; g += whites * factor; b += whites * factor;
}
if (lum &lt; 0.2) {
const factor = (0.2 - lum) * 5;
r -= blacks * factor; g -= blacks * factor; b -= blacks * factor;
}
// é™å¹…
data[i]   = Math.min(255, Math.max(0, r * 255));
data[i+1] = Math.min(255, Math.max(0, g * 255));
data[i+2] = Math.min(255, Math.max(0, b * 255));
}
// æ›´æ–°é¢„è§ˆ
previewCtx.putImageData(imgData, 0, 0);
updateHistogram(imgData);
}

function updateHistogram(imageData) {
const bins = 256;
const counts = new Array(bins).fill(0);
const data = imageData.data;
for (let i = 0; i &lt; data.length; i += 4) {
// ç°åº¦å€¼
const lum = Math.round(0.299*data[i] + 0.587*data[i+1] + 0.114*data[i+2]);
counts[lum]++;
}
const labels = counts.map((_,i) =&gt; i);
if (!histChart) {
histChart = new Chart(histCtx, {
type: 'bar',
data: {
labels,
datasets: [{ label: 'åƒç´ æ•°', data: counts, backgroundColor: 'rgba(0,0,0,0.5)' }]
},
options: {
responsive: true,
scales: { x: { display: false }, y: { beginAtZero: true } },
plugins: { legend: { display: false } }
}
});
} else {
histChart.data.datasets[0].data = counts;
histChart.update();
}
}
&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
````ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/tu-xiang-zhi-fang-tu-zai-xian-diao-jie.html</guid><pubDate>Sun, 20 Jul 2025 04:49:40 +0000</pubDate></item><item><title>å›¾åƒåˆ†ç±»è„šæœ¬</title><link>https://feeday.cn/post/tu-xiang-fen-lei-jiao-ben.html</link><description>## ResNet50
```
import subprocess
import sys

# è‡ªåŠ¨å®‰è£…ä¾èµ–
def install_packages():
    packages = ['torch', 'torchvision', 'pillow', 'pandas', 'openpyxl', 'requests']
    for pkg in packages:
        try:
            __import__(pkg)
        except ImportError:
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])

install_packages()

# === å¯¼å…¥ä¾èµ– ===
import os
import shutil
import torch
from torchvision import models, transforms
from PIL import Image
import pandas as pd
from collections import defaultdict
import requests

# === å›¾åƒé¢„å¤„ç†ï¼ˆImageNetï¼‰===
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# === åŠ è½½ ResNet50 æ¨¡å‹ ===
model = models.resnet50(pretrained=True)
model.eval()

# === åŠ è½½ç±»åˆ«æ ‡ç­¾ ===
# https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt

LABELS_PATH = r'g:\Dataset\Image\COCO_Annotations\imagenet_classes.txt'
with open(LABELS_PATH, 'r', encoding='utf-8') as f:
    labels = f.read().strip().split('\n')


# === å•å¼ å›¾åƒåˆ†ç±» ===
def classify_image(image_path):
    image = Image.open(image_path).convert('RGB')
    input_tensor = transform(image).unsqueeze(0)
    with torch.no_grad():
        output = model(input_tensor)
        probs = torch.nn.functional.softmax(output[0], dim=0)
        top1_prob, top1_class = torch.topk(probs, 1)
    return labels[top1_class.item()], top1_prob.item()

# === åˆ†ç±»ä¸»æµç¨‹ ===
def organize_images_by_class(src_dir, dst_dir):
    records = []
    class_counts = defaultdict(int)

    for fname in os.listdir(src_dir):
        if not fname.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.png')):
            continue

        img_path = os.path.join(src_dir, fname)
        predicted_class, prob = classify_image(img_path)
        class_folder = os.path.join(dst_dir, predicted_class)
        os.makedirs(class_folder, exist_ok=True)

        shutil.copy(img_path, os.path.join(class_folder, fname))
        records.append({
            'æ–‡ä»¶å': fname,
            'é¢„æµ‹ç±»åˆ«': predicted_class,
            'ç½®ä¿¡åº¦': round(prob, 4)
        })
        class_counts[predicted_class] += 1

    # ä¿å­˜ç»“æœåˆ° Excel
    df = pd.DataFrame(records)
    count_df = pd.DataFrame([
        {'é¢„æµ‹ç±»åˆ«': k, 'å›¾ç‰‡æ•°é‡': v}
        for k, v in sorted(class_counts.items(), key=lambda x: -x[1])
    ])
    output_excel = os.path.join(dst_dir, 'result.xlsx')
    with pd.ExcelWriter(output_excel) as writer:
        df.to_excel(writer, index=False, sheet_name='åˆ†ç±»ç»“æœ')
        count_df.to_excel(writer, index=False, sheet_name='ç±»åˆ«æ±‡æ€»')

    print(f'\nâœ… åˆ†ç±»å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ {output_excel}')
    print(f'ğŸ“ åˆ†ç±»åçš„æ–‡ä»¶ä½äº: {dst_dir}')

# === å‘½ä»¤è¡Œå…¥å£ ===
if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(description='å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»å¹¶å¤åˆ¶åˆ°å¯¹åº”ç±»åˆ«ç›®å½•')
    parser.add_argument('--src', default=r'G:\Dataset\Image\images', help='åŸå§‹å›¾åƒè·¯å¾„')
    parser.add_argument('--dst', default=r'G:\Dataset\Image\tag', help='åˆ†ç±»ç»“æœä¿å­˜è·¯å¾„')
    args = parser.parse_args()

    organize_images_by_class(args.src, args.dst)
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/tu-xiang-fen-lei-jiao-ben.html</guid><pubDate>Sun, 20 Jul 2025 04:49:00 +0000</pubDate></item><item><title>typecho å¯†ç å¿˜è®°å¯†ç  sqlite æ•°æ®åº“</title><link>https://feeday.cn/post/typecho%20-mi-ma-wang-ji-mi-ma-%20sqlite%20-shu-ju-ku.html</link><description>åšå®¢å¿˜è®°äº†å¯†ç å¯ä»¥ç”¨ä»¥ä¸‹æ–¹æ³•æ‰¾å›å¯†ç ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/typecho%20-mi-ma-wang-ji-mi-ma-%20sqlite%20-shu-ju-ku.html</guid><pubDate>Sun, 20 Jul 2025 04:48:22 +0000</pubDate></item><item><title>åœ¨çº¿æ–‡ä»¶åŠ å¯†è§£å¯†</title><link>https://feeday.cn/post/zai-xian-wen-jian-jia-mi-jie-mi.html</link><description>huggingface  spaces gradio

## requirements.txt
```
gradio
cryptography
```

## app.py

```
import gradio as gr
from cryptography.fernet import Fernet
import os

# AES åŠ å¯†å‡½æ•°ï¼ˆFernet å®ç°ï¼‰
def encrypt_file_gr(file):
    file_path = file.name
    key = Fernet.generate_key()
    cipher = Fernet(key)
    with open(file_path, 'rb') as f:
        data = f.read()
    encrypted_data = cipher.encrypt(data)
    enc_path = file_path + '.enc'
    with open(enc_path, 'wb') as f:
        f.write(encrypted_data)
    return key.decode(), enc_path

# AES è§£å¯†å‡½æ•°ï¼Œæ¢å¤åŸå§‹æ–‡ä»¶åå’Œæ ¼å¼
def decrypt_file_gr(file, key):
    file_path = file.name
    cipher = Fernet(key.encode())
    try:
        with open(file_path, 'rb') as f:
            encrypted_data = f.read()
        decrypted_data = cipher.decrypt(encrypted_data)
        # å»æ‰ .enc åç¼€ï¼Œæ¢å¤åŸå§‹æ–‡ä»¶å
        if file_path.lower().endswith('.enc'):
            dec_path = file_path[:-4]
        else:
            dec_path = file_path + '.dec'
        with open(dec_path, 'wb') as f:
            f.write(decrypted_data)
        return dec_path
    except Exception:
        return None

# Gradio ç•Œé¢è®¾è®¡
with gr.Blocks() as demo:
    gr.Markdown('# æ–‡ä»¶åŠ å¯†è§£å¯†å·¥å…·')

    with gr.Tab('åŠ å¯†'):
        encrypt_in = gr.File(label='ä¸Šä¼ æ–‡ä»¶')
        encrypt_btn = gr.Button('åŠ å¯†æ–‡ä»¶ ğŸ”’')
        # æ–‡æœ¬æ¡†æ˜¾ç¤ºå¯†é’¥å¹¶æä¾›å¤åˆ¶æŒ‰é’®
        encrypt_key = gr.Textbox(label='ç”Ÿæˆçš„å¯†é’¥', interactive=False, show_copy_button=True)
        encrypt_out = gr.File(label='ä¸‹è½½åŠ å¯†æ–‡ä»¶ (.enc)')
        encrypt_btn.click(
            fn=encrypt_file_gr,
            inputs=encrypt_in,
            outputs=[encrypt_key, encrypt_out]
        )

    with gr.Tab('è§£å¯†'):
        decrypt_in = gr.File(label='ä¸Šä¼ åŠ å¯†æ–‡ä»¶ (.enc)')
        decrypt_key_in = gr.Textbox(label='è¾“å…¥å¯†é’¥')
        decrypt_btn = gr.Button('è§£å¯†æ–‡ä»¶ ğŸ”“')
        decrypt_out = gr.File(label='ä¸‹è½½è§£å¯†æ–‡ä»¶ï¼ˆåŸå§‹æ ¼å¼ï¼‰')
        decrypt_btn.click(
            fn=decrypt_file_gr,
            inputs=[decrypt_in, decrypt_key_in],
            outputs=decrypt_out
        )

if __name__ == '__main__':
    demo.launch()
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/zai-xian-wen-jian-jia-mi-jie-mi.html</guid><pubDate>Sun, 20 Jul 2025 04:47:52 +0000</pubDate></item><item><title>è§†é¢‘æå–å›¾åƒ</title><link>https://feeday.cn/post/shi-pin-ti-qu-tu-xiang.html</link><description>```
import os
import cv2
from pathlib import Path

# æŒ‡å®šè§†é¢‘æ‰€åœ¨ç›®å½•
video_dir = r'c:\video'  # ä¿®æ”¹ä¸ºä½ çš„è§†é¢‘ç›®å½•
output_dir = r'c:\img'  # ä¿å­˜å›¾ç‰‡çš„ç›®å½•

# æ¯ç§’æå–å¸§æ•°
frames_per_second = 1  # æ¯ç§’æå–1å¸§

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
Path(output_dir).mkdir(parents=True, exist_ok=True)

# éå†æŒ‡å®šç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
for filename in os.listdir(video_dir):
    if filename.endswith(('.mp4', '.avi', '.mov', '.mkv')):  # æ ¹æ®è§†é¢‘æ ¼å¼è°ƒæ•´
        video_path = os.path.join(video_dir, filename)

        # ä½¿ç”¨ OpenCV æ‰“å¼€è§†é¢‘æ–‡ä»¶
        cap = cv2.VideoCapture(video_path)

        # è·å–è§†é¢‘çš„å¸§ç‡
        fps = cap.get(cv2.CAP_PROP_FPS)
        print(f'è§†é¢‘ {filename} çš„å¸§ç‡: {fps} å¸§/ç§’')

        frame_count = 0
        saved_frame_count = 0

        while True:
            ret, frame = cap.read()

            # å¦‚æœè¯»å–æˆåŠŸ
            if ret:
                frame_count += 1

                # æ¯éš”ä¸€å®šå¸§æ•°ï¼ˆæ ¹æ®fpsè®¡ç®—æ¯ç§’æå–1å¸§ï¼‰
                if frame_count % int(fps / frames_per_second) == 0:
                    # ä½¿ç”¨ pathlib å¤„ç†è·¯å¾„å’Œæ–‡ä»¶å
                    image_filename = Path(filename).stem + f'_{saved_frame_count + 1}.jpg'
                    image_path = Path(output_dir) / image_filename

                    # ä¿å­˜å›¾ç‰‡
                    cv2.imwrite(str(image_path), frame)
                    saved_frame_count += 1
                    print(f'ä¿å­˜å›¾ç‰‡ï¼š{image_path}')
            else:
                break  # å¦‚æœæ²¡æœ‰æ›´å¤šå¸§å¯è¯»å–ï¼Œè·³å‡ºå¾ªç¯

        # é‡Šæ”¾è§†é¢‘å¯¹è±¡
        cap.release()

print('æ‰€æœ‰è§†é¢‘çš„å¸§æå–å®Œæ¯•ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shi-pin-ti-qu-tu-xiang.html</guid><pubDate>Sun, 20 Jul 2025 04:47:14 +0000</pubDate></item><item><title>å¯¼å‡ºdocxæ–‡æ¡£é‡Œçš„å›¾åƒ</title><link>https://feeday.cn/post/dao-chu-docx-wen-dang-li-de-tu-xiang.html</link><description>## æ‰§è¡Œç»“æœ
```
f:/doc/
â”‚
â”œâ”€â”€ document1.docx
â”œâ”€â”€ document2.docx
â””â”€â”€ document3.docx
```

```
f:/doc/png/
â”‚
â”œâ”€â”€ document1/
â”‚   â”œâ”€â”€ document1.txt      # Contains the extracted text (e.g., 'å›¾ç‰‡ç®€ä»‹ï¼šdescription text')
â”‚   â”œâ”€â”€ document1_000001.png  # Image extracted from the document, renamed based on the corresponding text
â”‚   â”œâ”€â”€ document1_000002.png  # Another image
â”‚   â””â”€â”€ document1_000003.png  # Another image
â”‚
â”œâ”€â”€ document2/
â”‚   â”œâ”€â”€ document2.txt
â”‚   â”œâ”€â”€ document2_000001.png
â”‚   â”œâ”€â”€ document2_000002.png
â”‚   â””â”€â”€ document2_000003.png
â”‚
â””â”€â”€ document3/
    â”œâ”€â”€ document3.txt
    â”œâ”€â”€ document3_000001.png
    â”œâ”€â”€ document3_000002.png
    â””â”€â”€ document3_000003.png
```


##  å®Œæ•´ä»£ç 
```
from docx import Document
import os
import re
import shutil
 
# pip install python-docx
# pip install lxml  # é€šå¸¸ä¸å¿…éœ€ï¼Œé™¤éåœ¨å®‰è£… python-docx åå‡ºç°é—®é¢˜
 
 
def get_picture(document, paragraph):
    '''
    ä»æ®µè½ä¸­è·å–å›¾ç‰‡
    '''
    img = paragraph._element.xpath('.//pic:pic')
    if not img:
        return None
    img = img[0]
    embed = img.xpath('.//a:blip/@r:embed')[0]
    related_part = document.part.related_parts[embed]
    image = related_part.image
    return image
 
def extract_content(docx_path, output_dir):
    try:
        doc = Document(docx_path)
        base_filename = os.path.splitext(os.path.basename(docx_path))[0]
        doc_output_dir = os.path.join(output_dir, base_filename)
        os.makedirs(doc_output_dir, exist_ok=True)
        shutil.copy(docx_path, doc_output_dir)
 
        extracted_text = []
        extracted_images = []
 
        for para in doc.paragraphs:
            match = re.search(r'å›¾ç‰‡ç®€ä»‹ï¼š(.*)', para.text)
            if match:
                violation_text = match.group(1).strip() if match.group(1).strip() else 'XXX'
                extracted_text.append(violation_text)
 
            image = get_picture(doc, para)
            if image:
                blob = image.blob
                image_index = len(extracted_images) + 1
                formatted_index = f'{image_index:06d}'
                img_path = os.path.join(doc_output_dir, f'{base_filename}_{formatted_index}.png')
                extracted_images.append(img_path)
                with open(img_path, 'wb') as f:
                    f.write(blob)
 
        if extracted_text:
            text_filename = f'{base_filename}.txt'
            text_path = os.path.join(doc_output_dir, text_filename)
            with open(text_path, 'w', encoding='utf-8') as text_file:
                text_file.write('\n'.join(extracted_text))
            rename_images_based_on_text(doc_output_dir, text_path, extracted_images)
 
    except Exception as e:
        print(f'Error processing {docx_path}: {e}')
 
def rename_images_based_on_text(output_dir, text_file_path, extracted_images):
    with open(text_file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()
 
    if len(extracted_images) != len(lines):
        print(f'Error: The number of images ({len(extracted_images)}) and text lines ({len(lines)}) do not match in {output_dir}.')
        return
 
    for image_path, line in zip(extracted_images, lines):
        new_image_name = f'{os.path.splitext(image_path)[0]}_{line.strip()}{os.path.splitext(image_path)[1]}'
        os.rename(image_path, new_image_name)
        print(f'Renamed '{image_path}' to '{new_image_name}'')
 
def process_documents(folder_path, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    for filename in os.listdir(folder_path):
        if filename.endswith('.docx') or filename.endswith('.doc'):
            docx_path = os.path.join(folder_path, filename)
            extract_content(docx_path, output_folder)
 
# ç¤ºä¾‹ç”¨æ³•
folder_path = 'f:/doc'
output_folder = 'f:/doc/png'
process_documents(folder_path, output_folder)
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/dao-chu-docx-wen-dang-li-de-tu-xiang.html</guid><pubDate>Sun, 20 Jul 2025 04:46:40 +0000</pubDate></item><item><title>åˆ›å»ºæŒ‡å®šå¤§å°æ–‡ä»¶</title><link>https://feeday.cn/post/chuang-jian-zhi-ding-da-xiao-wen-jian.html</link><description>è¿è¡Œ cmd æ‰§è¡Œåˆ›å»ºæ–‡æœ¬æ–‡ä»¶

```
fsutil file createnew f:\1GB.txt 1073741824
```

æ¢ç®—å•ä½

```
byte (B):1073741824
kilobyte (kB):1048576
megabyte (MB):1024
gigabyte (GB):	1
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/chuang-jian-zhi-ding-da-xiao-wen-jian.html</guid><pubDate>Sun, 20 Jul 2025 04:46:02 +0000</pubDate></item><item><title>è·å–ç½‘é¡µé“¾æ¥</title><link>https://feeday.cn/post/huo-qu-wang-ye-lian-jie.html</link><description>æ§åˆ¶å°æµè§ˆå™¨è·å–ç½‘å€

## bilibili
```
const links = document.getElementsByTagName('a');
// éå†æ‰€æœ‰é“¾æ¥å¹¶æŸ¥æ‰¾åŒ¹é…çš„ç½‘å€
for (const link of links) {
  const href = link.href;
  // ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ç±»ä¼¼çš„ç½‘å€
  const urlRegex = /https:\/\/www\.bilibili\.com\/video\/[A-Za-z0-9]+\/?/;
  if (urlRegex.test(href)) {
    console.log('åŒ¹é…åˆ°çš„ç½‘å€: ' + href);
  }
}
```

## youtube

```
const links = document.getElementsByTagName('a');

// éå†æ‰€æœ‰é“¾æ¥å¹¶æŸ¥æ‰¾åŒ¹é…çš„ç½‘å€
for (const link of links) {
  const href = link.href;
  // ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… YouTube è§†é¢‘é“¾æ¥
  const urlRegex = /https:\/\/www\.youtube\.com\/watch\?v=[A-Za-z0-9_-]+/;
  if (urlRegex.test(href)) {
    console.log('åŒ¹é…åˆ°çš„ç½‘å€: ' + href);
  }
}
```
## dataset
```
const links = document.getElementsByTagName('a');

// éå†æ‰€æœ‰é“¾æ¥å¹¶æŸ¥æ‰¾åŒ¹é… Hugging Face blob åœ°å€
for (const link of links) {
  const href = link.href;
  // åŒ¹é… datasets ä»“åº“ blob é“¾æ¥
  const urlRegex = /^https:\/\/huggingface\.co\/datasets\/[^/]+\/[^/]+\/blob\/[^/]+\/.+$/;
  if (urlRegex.test(href)) {
    // æ›¿æ¢ blob â†’ resolve
    const realUrl = href.replace('/blob/', '/resolve/');
    console.log('ç›´é“¾: ' + realUrl);
  }
}
```
ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/huo-qu-wang-ye-lian-jie.html</guid><pubDate>Sun, 20 Jul 2025 04:45:35 +0000</pubDate></item><item><title>æŸ¥æ‰¾æ›¿æ¢</title><link>https://feeday.cn/post/cha-zhao-ti-huan.html</link><description>æœç´¢åŒ¹é…å½“å‰ç›®å½•ä¸‹æ‰€æœ‰[æ–‡ä»¶å]æˆ–æ–‡ä»¶é‡Œçš„å†…å®¹æ‰“å°æ˜¾ç¤ºè¡Œå·
```
grep -rn 'Money' *
```

æœç´¢å¤šä¸ªæ–‡ä»¶å¹¶æŸ¥æ‰¾åŒ¹é…æ–‡æœ¬åœ¨å“ªäº›æ–‡ä»¶ä¸­ï¼š
```
grep -l 'Money' file1 file2 file3...
```

æŸ¥æ‰¾ formatting.php æ–‡ä»¶å†… lengthâ€™, 55 æ›¿æ¢ lengthâ€™, 56 :
```
sed -i s/'length', 55'/'length', 56'/g `grep 'length', 55' -rl --include='formatting.php' ./`
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/cha-zhao-ti-huan.html</guid><pubDate>Sun, 20 Jul 2025 04:45:05 +0000</pubDate></item><item><title>ç§»åˆ°æ–‡ä»¶</title><link>https://feeday.cn/post/yi-dao-wen-jian.html</link><description>### æŒ‰ç…§æŒ‡å®šæ–‡ä»¶åç§»åˆ°æ–‡ä»¶

### ç®€ä»‹
å‡è®¾ç›®å½•ä¸æ–‡ä»¶å¦‚ä¸‹ï¼š
```
H:\
â”œâ”€ data
â”‚   â”œâ”€ report1.txt
â”‚   â”œâ”€ image_fail.png
â”‚   â””â”€ sub
â”‚       â””â”€ test_error.log
â”œâ”€ list.txt
â””â”€ copy    ï¼ˆåˆå§‹ä¸ºç©ºï¼‰
```

list.txt å†…å®¹ï¼ˆæ¯è¡Œä¸€ä¸ªå…³é”®å­—ï¼‰
```
report
fail
missing
error
```

è¿è¡Œæ§åˆ¶å°è¾“å‡ºï¼š
```
âœ” å·²ç§»åŠ¨: 'report1.txt' å¯¹åº”å…³é”®å­— 'report' åˆ° 'H:\copy\report1.txt'
âœ” å·²ç§»åŠ¨: 'image_fail.png' å¯¹åº”å…³é”®å­— 'fail' åˆ° 'H:\copy\image_fail.png'
âš  æœªæ‰¾åˆ°åŒ¹é…æ–‡ä»¶ for key: 'missing'
âœ” å·²ç§»åŠ¨: 'test_error.log' å¯¹åº”å…³é”®å­— 'error' åˆ° 'H:\copy\test_error.log'
 
å…± 4 ä¸ªå…³é”®å­—ï¼ŒæˆåŠŸç§»åŠ¨ 3 ä¸ªï¼Œå¯¹åº”æ–‡ä»¶ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/yi-dao-wen-jian.html</guid><pubDate>Sun, 20 Jul 2025 04:44:19 +0000</pubDate></item><item><title>åˆ é™¤é‡å¤å›¾åƒ</title><link>https://feeday.cn/post/shan-chu-zhong-fu-tu-xiang.html</link><description>```
import os
import cv2
import numpy as np
from keras.applications.resnet50 import ResNet50, preprocess_input
 
# pip install opencv-python numpy keras tensorflow
 
def extract_image_features(image_path):
    image = cv2.imread(image_path)  # è¯»å–å›¾ç‰‡
    image = cv2.resize(image, (256, 256))  # ç¼©æ”¾å›¾ç‰‡åˆ°ç»Ÿä¸€å°ºå¯¸
    image = image[16:240, 16:240]  # è£å‰ªä¸­é—´åŒºåŸŸ(224x224)
    
    image = np.expand_dims(image, axis=0)  # æ‰©å±•ç»´åº¦ä»¥åŒ¹é…æ¨¡å‹è¾“å…¥è¦æ±‚
    image = preprocess_input(image)  # é¢„å¤„ç†å›¾ç‰‡
    
    features = model.predict(image)  # æå–ç‰¹å¾å‘é‡
    features /= np.linalg.norm(features)  # å½’ä¸€åŒ–ç‰¹å¾å‘é‡
    
    return features.flatten()  # å¹³é“ºç‰¹å¾å‘é‡
 
def delete_duplicate_images():
    current_dir = os.getcwd()  # è·å–å½“å‰ç›®å½•è·¯å¾„
    files = [f for f in os.listdir(current_dir) if os.path.isfile(os.path.join(current_dir, f))]  # è·å–å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
 
    image_features = {}
    deleted_count = 0  # è®°å½•åˆ é™¤çš„å›¾ç‰‡æ•°é‡
    duplicate_pairs = []  # ç”¨äºä¿å­˜é‡å¤å›¾ç‰‡çš„æ–‡ä»¶åå¯¹
 
    for file_name in files:
        if file_name.endswith('.jpg') or file_name.endswith('.png'):  # ç­›é€‰å‡ºå›¾ç‰‡æ–‡ä»¶
            file_path = os.path.join(current_dir, file_name)
            image_feature = extract_image_features(file_path)
 
            is_duplicate = False
            for existing_path, existing_feature in image_features.items():
                distance = np.linalg.norm(existing_feature - image_feature)  # è®¡ç®—æ¬§æ°è·ç¦»
                if distance &lt; 0.3:  # è®¾å®šé˜ˆå€¼æ¥åˆ¤æ–­ç›¸ä¼¼åº¦ï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
                    is_duplicate = True
                    print(f'åˆ é™¤é‡å¤å›¾ç‰‡: {file_path}')
                    os.remove(file_path)
                    deleted_count += 1
                    # è®°å½•é‡å¤çš„æ–‡ä»¶åå¯¹ (å½“å‰æ–‡ä»¶åå’Œå·²æœ‰æ–‡ä»¶å)
                    duplicate_pairs.append((file_name, os.path.basename(existing_path)))
                    break
 
            if not is_duplicate:
                image_features[file_path] = image_feature
 
    # å°†é‡å¤å›¾ç‰‡æ–‡ä»¶åå¯¹ä¿å­˜åˆ°txtæ–‡ä»¶
    if duplicate_pairs:
        with open('duplicate_images.txt', 'w') as f:
            for file1, file2 in duplicate_pairs:
                f.write(f'{file1} ä¸ {file2} é‡å¤\n')
    
    print('å·²åˆ é™¤ {} å¼ é‡å¤å›¾ç‰‡'.format(deleted_count))
 
# åŠ è½½é¢„è®­ç»ƒçš„ResNet50æ¨¡å‹
model = ResNet50(weights='imagenet', include_top=False, pooling='avg')
 
delete_duplicate_images()
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shan-chu-zhong-fu-tu-xiang.html</guid><pubDate>Sun, 20 Jul 2025 04:43:13 +0000</pubDate></item><item><title>md5å¤„ç†æ–‡ä»¶</title><link>https://feeday.cn/post/md5-chu-li-wen-jian.html</link><description>## åˆ é™¤MD5å€¼ç›¸åŒçš„æ–‡ä»¶

é€šè¿‡MD5å€¼æŠŠé‡å¤çš„æ–‡ä»¶ç§»åˆ°delæ–‡ä»¶å¤¹ï¼Œè¡¨æ ¼è®°å½•ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/md5-chu-li-wen-jian.html</guid><pubDate>Sun, 20 Jul 2025 04:42:26 +0000</pubDate></item><item><title>åŒæ­¥ä»£ç </title><link>https://feeday.cn/post/tong-bu-dai-ma.html</link><description>## å¸¸ç”¨çš„ Git å‘½ä»¤

æ›´æ–°ç«¯å£åˆ·æ–°DNS

```
git config --global http.proxy 127.0.0.1:7890
git config --global https.proxy 127.0.0.1:7890
ipconfig/flushdns
```
### ä»£ç ä»“åº“æ‹‰å–æ¨é€

- https://github.com/settings/ssh/new
- https://huggingface.co/settings/keys/add?type=ssh

æ‹‰å–ä»“åº“æœ¬åœ°åˆ°æœ¬åœ°æ¨é€åˆ°è¿œç¨‹ä»“åº“

```
git clone https://github.com/lllyasviel/Fooocus.git
git config --global user.email 'you@example.com'
git config --global user.name 'Your Name'
git remote set-url origin git@github.com:lllyasviel/Fooocus.git
ssh-keygen -t rsa -b 4096 -C 'your_email@example.com'
ssh -T git@github.com
git add . 
git commit -m 'Test' 
```

æœ¬åœ°æ¨é€åˆ°è¿œç¨‹ä»“åº“
```
git push origin main
```
è¿œç¨‹ä»“åº“åŒæ­¥åˆ°æœ¬åœ° 
```
git pull origin main  
```

### 1. **å…‹éš†è¿œç¨‹ä»“åº“**

å…‹éš†ä¸€ä¸ªè¿œç¨‹ä»“åº“åˆ°æœ¬åœ°ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼š

```bash
git clone https://github.com/lllyasviel/Fooocus.git
```

### 2. **æ£€æŸ¥å½“å‰ Git é…ç½®**

æŸ¥çœ‹ Git çš„å…¨å±€é…ç½®ï¼Œå¦‚ç”¨æˆ·åå’Œé‚®ç®±ï¼š

```bash
git config --list
```

### 3. **æ£€æŸ¥å½“å‰çŠ¶æ€**

æŸ¥çœ‹å½“å‰å·¥ä½œç›®å½•å’Œæš‚å­˜åŒºçš„çŠ¶æ€ï¼ˆå“ªäº›æ–‡ä»¶å·²ä¿®æ”¹ã€æœªè·Ÿè¸ªç­‰ï¼‰ï¼š

```bash
git status
```

### 4. **æ·»åŠ æ–‡ä»¶åˆ°æš‚å­˜åŒº**

å°†æ–‡ä»¶æ·»åŠ åˆ°æš‚å­˜åŒºï¼Œå‡†å¤‡æäº¤ï¼š

```bash
git add &lt;file_name&gt;  # æ·»åŠ æŒ‡å®šæ–‡ä»¶
git add .  # æ·»åŠ æ‰€æœ‰ä¿®æ”¹çš„æ–‡ä»¶
```

### 5. **æäº¤æ›´æ”¹**

æäº¤æ›´æ”¹å¹¶æ·»åŠ æäº¤ä¿¡æ¯ï¼š

```bash
git commit -m 'æè¿°æœ¬æ¬¡æäº¤çš„å†…å®¹'
```

### 6. **æ¨é€è¿œç¨‹ä»“åº“**

å°†æœ¬åœ°æ›´æ”¹æ¨é€åˆ°è¿œç¨‹ä»“åº“ï¼š

```bash
git push origin branch-name
```

### 7. **è¿œç¨‹ä»“åº“æ›´æ–°**

æ‹‰å–è¿œç¨‹ä»“åº“çš„æ›´æ–°ï¼Œå¹¶åˆå¹¶åˆ°å½“å‰åˆ†æ”¯ï¼š

```bash
git pull origin branch-name
```

### 8. **æŸ¥çœ‹è¿œç¨‹ä»“åº“ä¿¡æ¯**

æŸ¥çœ‹å½“å‰é¡¹ç›®çš„è¿œç¨‹ä»“åº“åœ°å€ï¼š

```bash
git remote -v
```

### 9. **æŸ¥çœ‹æäº¤å†å²**

æŸ¥çœ‹æäº¤å†å²è®°å½•ï¼š

```bash
git log
```

### 10. **åˆ›å»ºæ–°åˆ†æ”¯**

åˆ›å»ºä¸€ä¸ªæ–°åˆ†æ”¯ï¼Œå¹¶åˆ‡æ¢åˆ°è¯¥åˆ†æ”¯ï¼š

```bash
git checkout -b new-branch-name
```

### 11. **åˆ‡æ¢åˆ†æ”¯**

åˆ‡æ¢åˆ°å·²æœ‰çš„åˆ†æ”¯ï¼š

```bash
git checkout branch-name
```

### 12. **åˆå¹¶åˆ†æ”¯**

å°†å½“å‰åˆ†æ”¯åˆå¹¶åˆ°ç›®æ ‡åˆ†æ”¯ï¼š

```bash
git merge branch-name
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/tong-bu-dai-ma.html</guid><pubDate>Sun, 20 Jul 2025 04:41:37 +0000</pubDate></item><item><title>æŸ¥æ‰¾ä»£ç </title><link>https://feeday.cn/post/cha-zhao-dai-ma.html</link><description>## Windows æŸ¥æ‰¾
```
Get-ChildItem -Recurse -File | Select-String -Pattern '56'
```
## Bash æŸ¥æ‰¾
æœç´¢åŒ¹é…å½“å‰ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶åæˆ–æ–‡ä»¶é‡Œçš„å†…å®¹æ‰“å°æ˜¾ç¤ºè¡Œå·
```
grep -rn 'Money' *
```
æœç´¢å¤šä¸ªæ–‡ä»¶å¹¶æŸ¥æ‰¾åŒ¹é…æ–‡æœ¬åœ¨å“ªäº›æ–‡ä»¶ä¸­ï¼š
```
grep -l 'Money' file1 file2 file3...
```
æŸ¥æ‰¾ formatting.php æ–‡ä»¶å†… lengthâ€™, 55 æ›¿æ¢ lengthâ€™, 56 :

```
sed -i s/'length', 55'/'length', 56'/g `grep 'length', 55' -rl --include='formatting.php' ./`
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/cha-zhao-dai-ma.html</guid><pubDate>Sun, 20 Jul 2025 04:40:46 +0000</pubDate></item><item><title>NextChat</title><link>https://feeday.cn/post/NextChat.html</link><description>

âœ¨ Light and Fast AI Assistant,with Claude, DeepSeek, GPT4 &amp; Gemini Pro support. 


[NextChatAI](https://nextchat.club?utm_source=readme) / [Web App Demo](https://app.nextchat.dev) / [Desktop App](https://github.com/Yidadaa/ChatGPT-Next-Web/releases) / [Discord](https://discord.gg/YCkeafCafC) / [Enterprise Edition](#enterprise-edition) / [Twitter](https://twitter.com/NextChatDev)


[saas-url]: https://nextchat.club?utm_source=readme
[saas-image]: https://img.shields.io/badge/NextChat-Saas-green?logo=microsoftedge
[web-url]: https://app.nextchat.dev/
[download-url]: https://github.com/Yidadaa/ChatGPT-Next-Web/releases
[Web-image]: https://img.shields.io/badge/Web-PWA-orange?logo=microsoftedge
[Windows-image]: https://img.shields.io/badge/-Windows-blue?logo=windows
[MacOS-image]: https://img.shields.io/badge/-MacOS-black?logo=apple
[Linux-image]: https://img.shields.io/badge/-Linux-333?logo=ubuntu

[&lt;img src='https://zeabur.com/button.svg' alt='Deploy on Zeabur' height='30'&gt;](https://zeabur.com/templates/ZBUEFA) [&lt;img src='https://vercel.com/button' alt='Deploy on Vercel' height='30'&gt;](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FChatGPTNextWeb%2FChatGPT-Next-Web&amp;env=OPENAI_API_KEY&amp;env=CODE&amp;project-name=nextchat&amp;repository-name=NextChat)  [&lt;img src='https://gitpod.io/button/open-in-gitpod.svg' alt='Open in Gitpod' height='30'&gt;](https://gitpod.io/#https://github.com/ChatGPTNextWeb/NextChat) 

[&lt;img src='https://github.com/user-attachments/assets/903482d4-3e87-4134-9af1-f2588fa90659' height='50' width='' &gt;](https://monica.im/?utm=nxcrp)



## Dokploy

Dokploy æ˜¯ä¸€ä¸ªå…è´¹çš„ã€å¯è‡ªæ‰˜ç®¡çš„å¹³å°å³æœåŠ¡ ï¼ˆPaaSï¼‰ï¼Œå¯ç®€åŒ–åº”ç”¨ç¨‹åºå’Œæ•°æ®åº“çš„éƒ¨ç½²å’Œç®¡ç†ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/NextChat.html</guid><pubDate>Sat, 19 Jul 2025 20:47:38 +0000</pubDate></item><item><title>åˆ›å»ºåšå®¢</title><link>https://feeday.cn/post/chuang-jian-bo-ke.html</link><description>## å®‰è£…æ­¥éª¤

1. ã€åˆ›å»ºä»“åº“ã€‘ç‚¹å‡»[é€šè¿‡æ¨¡æ¿åˆ›å»ºä»“åº“](https://github.com/new?template_name=Gmeek-template&amp;template_owner=Meekdai)ï¼Œå»ºè®®ä»“åº“åç§°ä¸º`XXX.github.io`ï¼Œå…¶ä¸­`XXX`ä¸ºä½ çš„githubç”¨æˆ·åã€‚</description><guid isPermaLink="true">https://feeday.cn/post/chuang-jian-bo-ke.html</guid><pubDate>Sat, 19 Jul 2025 17:50:50 +0000</pubDate></item></channel></rss>